{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "## Advanced Data Analytics - Algorithms and Machine Learning\n",
    "## 31005\n",
    "### Harrison Cole\n",
    "### 12962712"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Section 1 - Imports"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "outputs": [],
   "source": [
    "import abc\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from typing import Callable, Optional, Tuple\n",
    "from sklearn.datasets import load_iris as dataset\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Section 2 - Utility Function Definitions"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "outputs": [],
   "source": [
    "def require(value: Optional[any], field: str):\n",
    "    if value is None:\n",
    "        raise ValueError(f'Missing required value: \"{field}\".')\n",
    "    return value\n",
    "\n",
    "\n",
    "def default(value: Optional[any], otherwise: any) -> any:\n",
    "    return otherwise if value is None else value\n",
    "\n",
    "\n",
    "def is_numeric(x):\n",
    "    return x.dtype == int or x.dtype == float or x.dtype == bool\n",
    "\n",
    "\n",
    "def value_counts(y, normalise: bool = True):\n",
    "    values, counts = np.unique(y, return_counts=True)\n",
    "    if normalise:\n",
    "        return values, counts / np.sum(counts)\n",
    "    return values, counts\n",
    "\n",
    "def majority_class_index(data, attribute):\n",
    "    return np.argmax(np.unique(data[attribute], return_counts=True)[1])\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Section 3 - Datastructures, Interfaces and Implementations"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "outputs": [],
   "source": [
    "class SplitCriterionFunction(metaclass=abc.ABCMeta):\n",
    "\n",
    "    @abc.abstractmethod\n",
    "    def compute(self, frequencies) -> float:\n",
    "        pass\n",
    "\n",
    "\n",
    "class Entropy(SplitCriterionFunction):\n",
    "\n",
    "    def compute(self, frequencies, eps=1e-9) -> float:\n",
    "        return -(frequencies * np.log2(frequencies + eps)).sum()\n",
    "\n",
    "\n",
    "class GiniIndex(SplitCriterionFunction):\n",
    "\n",
    "    def compute(self, frequencies) -> float:\n",
    "        return 1 - np.sum(np.square(frequencies))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "outputs": [],
   "source": [
    "class TransformFunction(metaclass=abc.ABCMeta):\n",
    "\n",
    "    @abc.abstractmethod\n",
    "    def transform(self, value: any) -> any:\n",
    "        pass\n",
    "\n",
    "\n",
    "class IdentityTransformFunction(TransformFunction):\n",
    "\n",
    "    def transform(self, value: any) -> any:\n",
    "        return value\n",
    "\n",
    "\n",
    "class LookupTransformFunction(TransformFunction):\n",
    "\n",
    "    def __init__(self, transformer: Callable[[any], any]):\n",
    "        self.__transformer = require(transformer, 'transformer')\n",
    "\n",
    "    def transform(self, value: any) -> any:\n",
    "        return self.__transformer(value)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "outputs": [],
   "source": [
    "class Pivot:\n",
    "\n",
    "    def __init__(self, predicate: Callable[[any], bool], info: Tuple[any, any, str, str]):\n",
    "        self.__predicate = require(predicate, 'predicate')\n",
    "        self.__info = require(info, 'info')\n",
    "\n",
    "    @property\n",
    "    def predicate(self) -> Callable[[any], bool]:\n",
    "        return self.__predicate\n",
    "\n",
    "    def attribute(self) -> any:\n",
    "        return self.__info[0]\n",
    "\n",
    "    def subject(self) -> any:\n",
    "        return self.__info[1]\n",
    "\n",
    "    def true_condition(self) -> str:\n",
    "        return self.__info[2]\n",
    "\n",
    "    def false_condition(self) -> str:\n",
    "        return self.__info[3]\n",
    "\n",
    "    def split(self, value: any) -> bool:\n",
    "        return self.predicate(value)\n",
    "\n",
    "    # TODO: rename method as this is only used for splits on continuous attributes...\n",
    "    @staticmethod\n",
    "    def continuous(attribute, probe) -> 'Pivot':\n",
    "        def predicate(value: any) -> bool:\n",
    "            return value[attribute] <= probe\n",
    "        return Pivot(predicate=predicate, info=(attribute, probe, '<=', '>'))\n",
    "\n",
    "    def __str__(self, condition: bool = True) -> str:\n",
    "        operator: str = self.true_condition() if condition else self.false_condition()\n",
    "        return f'x[{self.attribute()}] {operator.ljust(2)} {self.subject()}'\n",
    "\n",
    "\n",
    "class PivotCandidate:\n",
    "\n",
    "    def __init__(self, feature: int, gain: float, probe: float):\n",
    "        self.__feature = feature\n",
    "        self.__gain = gain\n",
    "        self.__probe = probe\n",
    "\n",
    "    def feature(self) -> int:\n",
    "        return require(self.__feature, 'feature')\n",
    "\n",
    "    def gain(self) -> float:\n",
    "        return require(self.__gain, 'gain')\n",
    "\n",
    "    def probe(self) -> float:\n",
    "        return require(self.__probe, 'probe')\n",
    "\n",
    "    def update(self, feature: int, gain: float, probe: float) -> bool:\n",
    "        if gain < self.gain():\n",
    "            return False\n",
    "        self.__feature = feature\n",
    "        self.__gain = gain\n",
    "        self.__probe = probe\n",
    "        return True\n",
    "\n",
    "    @staticmethod\n",
    "    def initial() -> 'PivotCandidate':\n",
    "        return PivotCandidate(0, 0, 0.5)\n",
    "\n",
    "    def __str__(self):\n",
    "        return f'feature: {self.__feature}, gain: {self.__gain}, probe: {self.__probe}'\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "outputs": [],
   "source": [
    "class Node(metaclass=abc.ABCMeta):\n",
    "\n",
    "    @abc.abstractmethod\n",
    "    def eval(self, element: any) -> any:\n",
    "        raise NotImplementedError('Node#eval')\n",
    "\n",
    "    @staticmethod\n",
    "    def branch(pivot: 'Pivot', lower: Optional['Node'] = None, upper: Optional['Node'] = None) -> 'Node':\n",
    "        return BranchNode(pivot=pivot, lower=lower, upper=upper)\n",
    "\n",
    "    @staticmethod\n",
    "    def lookup(mapping: dict[any, 'Node'], feature: any) -> 'Node':\n",
    "        return LookupNode(mapping=mapping, feature=feature)\n",
    "\n",
    "    @staticmethod\n",
    "    def terminate(value: any) -> 'Node':\n",
    "        return TerminalNode(value=value)\n",
    "\n",
    "\n",
    "class BranchNode(Node):\n",
    "\n",
    "    __lower: Optional['Node']\n",
    "    __upper: Optional['Node']\n",
    "\n",
    "    def __init__(self, pivot: 'Pivot', lower: 'Node', upper: 'Node'):\n",
    "        self.__pivot = require(pivot, 'pivot')\n",
    "        self.__lower = require(lower, 'lower')\n",
    "        self.__upper = require(upper, 'upper')\n",
    "\n",
    "    def eval(self, element: any) -> any:\n",
    "        branch: Node = self.lower if self.pivot.split(element) else self.upper\n",
    "        return branch.eval(element)\n",
    "\n",
    "    @property\n",
    "    def pivot(self) -> 'Pivot':\n",
    "        return self.__pivot\n",
    "\n",
    "    @property\n",
    "    def lower(self) -> Optional['Node']:\n",
    "        return self.__lower\n",
    "\n",
    "    @property\n",
    "    def upper(self) -> Optional['Node']:\n",
    "        return self.__upper\n",
    "\n",
    "\n",
    "class LookupNode(Node):\n",
    "\n",
    "    __mapping: dict[any, 'Node']\n",
    "    __feature: any\n",
    "\n",
    "    def __init__(self, mapping: dict[any, 'Node'], feature: any):\n",
    "        self.__mapping = require(mapping, 'mapping')\n",
    "        self.__feature = require(feature, 'feature')\n",
    "\n",
    "    def eval(self, element: any) -> any:\n",
    "        value = element[self.feature]\n",
    "        branch: Node = require(self.mapping[value], 'branch')\n",
    "        return branch.eval(element)\n",
    "\n",
    "    @property\n",
    "    def mapping(self) -> dict[any, 'Node']:\n",
    "        return self.__mapping\n",
    "\n",
    "    @property\n",
    "    def feature(self) -> any:\n",
    "        return self.__feature\n",
    "\n",
    "\n",
    "class TerminalNode(Node):\n",
    "\n",
    "    def __init__(self, value: any):\n",
    "        self.__value = require(value, 'value')\n",
    "\n",
    "    def eval(self, element: any) -> any:\n",
    "        return self.value\n",
    "\n",
    "    @property\n",
    "    def value(self) -> any:\n",
    "        return require(self.__value, 'value')\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "outputs": [],
   "source": [
    "class DecisionTreeBuilder(metaclass=abc.ABCMeta):\n",
    "\n",
    "    __entropy: 'SplitCriterionFunction' = Entropy()\n",
    "    __gini: 'SplitCriterionFunction' = GiniIndex()\n",
    "\n",
    "    @abc.abstractmethod\n",
    "    def build(self, x, y) -> 'Node':\n",
    "        raise NotImplementedError('DecisionTreeBuilder#build')\n",
    "\n",
    "    # @staticmethod\n",
    "    # def compute_impurity(samples, criterion: str = 'entropy') -> float:\n",
    "    #     _, probabilities = value_counts(samples, normalise=True)\n",
    "    #     fns = {'entropy': Entropy, 'gini': GiniIndex}\n",
    "    #     fn: SplitCriterionFunction = require(fns.get(criterion, None), criterion)()\n",
    "    #     return fn.compute(probabilities)\n",
    "\n",
    "    def entropy(self, attributes):\n",
    "        _, probabilities = value_counts(attributes, normalise=True)\n",
    "        return self.__entropy.compute(frequencies=probabilities)\n",
    "\n",
    "    def information_gain(self, data, feature_attribute, target_attribute):\n",
    "        total_entropy = self.entropy(data[target_attribute])\n",
    "        feature_entropy = self.entropy(data[feature_attribute])\n",
    "        return total_entropy - feature_entropy\n",
    "\n",
    "    @staticmethod\n",
    "    def factory(implementation: str, **kwargs) -> 'DecisionTreeBuilder':\n",
    "        factories = {\n",
    "            'ID3': ID3DecisionTreeBuilder\n",
    "        }\n",
    "        constructor = require(factories.get(implementation, None), implementation)\n",
    "        return constructor(**kwargs)\n",
    "\n",
    "    @staticmethod\n",
    "    def default() -> 'DecisionTreeBuilder':\n",
    "        return DecisionTreeBuilder.factory('ID3')\n",
    "\n",
    "\n",
    "class ID3DecisionTreeBuilder(DecisionTreeBuilder):\n",
    "\n",
    "    # TODO: handle continuous attributes\n",
    "    # TODO: output classes in original format...\n",
    "    # TODO: mean value\n",
    "    def build(self, x, y) -> 'Node':\n",
    "        data = x.copy()\n",
    "        data[y.name] = y\n",
    "        return self._build(original=data, subset=data, features=x.columns, target=y.name)\n",
    "\n",
    "    def _build(self, original, subset, features, target, parent_class=None) -> 'Node':\n",
    "        \"\"\"\n",
    "        ID3 Algorithm as per: https://en.wikipedia.org/wiki/ID3_algorithm#Algorithm\n",
    "        \"\"\"\n",
    "        classes = np.unique(subset[target])\n",
    "        choices = len(classes)\n",
    "\n",
    "        # base case #1 - every element of the subset belongs to the same class.\n",
    "        if choices <= 1:\n",
    "            return Node.terminate(classes[0])\n",
    "\n",
    "        # base case #2 - there are no examples in the subset,\n",
    "        # which happens when no example in the parent set was\n",
    "        # found to match a specific value of the selected attribute\n",
    "        if len(subset) <= 0:\n",
    "            return Node.terminate(parent_class)\n",
    "\n",
    "        majority_index = majority_class_index(data=subset, attribute=target)\n",
    "        majority_class = classes[majority_index]\n",
    "\n",
    "        # base case #3 - there are no more attributes to be selected,\n",
    "        # but the examples still do not belong to the same class.\n",
    "        if len(features) <= 0:\n",
    "            return Node.terminate(majority_class)\n",
    "\n",
    "        information_gain = [self.information_gain(data=subset, feature_attribute=feature, target_attribute=target) for feature in features]\n",
    "        best_feature_index = np.argmax(information_gain)\n",
    "        best_feature = features[best_feature_index]\n",
    "\n",
    "        available_features = [feature for feature in features if feature != best_feature]\n",
    "        values = np.unique(subset[best_feature])\n",
    "\n",
    "        mapping: dict[any, Node] = {}\n",
    "\n",
    "        for value in values:\n",
    "            data = subset.where(subset[best_feature] == value).dropna()\n",
    "            subtree = self._build(original=original, subset=data, features=available_features, target=target, parent_class=majority_class)\n",
    "            mapping[value] = subtree\n",
    "\n",
    "        return Node.lookup(mapping=mapping, feature=best_feature)\n",
    "\n",
    "\n",
    "    # # TODO: handle categorical attributes...\n",
    "    # def build(self, x, y) -> 'Node':\n",
    "    #     classes = np.unique(y)\n",
    "    #     choices = len(classes)\n",
    "    #\n",
    "    #     if choices <= 0:  # edge-case: no choices\n",
    "    #         default_value = '<todo:default-value>'  # TODO: get default value\n",
    "    #         return Node.terminate(default_value)\n",
    "    #\n",
    "    #     if choices == 1:  # edge-case: one clear choice\n",
    "    #         return Node.terminate(classes[0])\n",
    "    #\n",
    "    #     candidate: PivotCandidate = PivotCandidate.initial()\n",
    "    #     attributes = x.shape[1]\n",
    "    #     for index in range(attributes):\n",
    "    #         # TODO: handle continuous and categorical attributes\n",
    "    #         attribute = x[:, index]  # array of all values at that index\n",
    "    #\n",
    "    #         print(f'attribute => {attribute}')\n",
    "    #         # print(f'build')\n",
    "    #         # print(f'index: {index}, attribute: {attribute}')\n",
    "    #         probes = ID3DecisionTreeBuilder.create_probe_values(attribute.min(), attribute.max())\n",
    "    #         # print(f'probes: {probes}')\n",
    "    #         for probe in probes:\n",
    "    #             gain = ID3DecisionTreeBuilder.compute_information_gain(y, attribute, probe)\n",
    "    #             # gain = np.random.random()\n",
    "    #\n",
    "    #             # gain = 0.0  # compute_gain(samples, attribute, target)\n",
    "    #             # gain = self.purity(attribute, probe, x, y)  # TODO: compute information gain\n",
    "    #             # gain = self.measure_progress(y, attribute, probe)\n",
    "    #             # gain = self.purity(attribute, )\n",
    "    #             candidate.update(feature=index, gain=gain, probe=probe)\n",
    "    #\n",
    "    #     # TODO: sanity check candidate or build pivot from candidate\n",
    "    #     pivot: Pivot = Pivot.continuous(candidate.feature(), candidate.probe())\n",
    "    #     # TODO: use or apply pivot data-structure and make more efficient...\n",
    "    #     idx_lower = x[:, candidate.feature()] <= candidate.probe()\n",
    "    #     idx_upper = x[:, candidate.feature()] > candidate.probe()\n",
    "    #\n",
    "    #     def build_index(indices) -> Node:\n",
    "    #         return self.build(x[indices], y[indices])\n",
    "    #\n",
    "    #     return Node.branch(pivot, build_index(idx_lower), build_index(idx_upper))\n",
    "    #\n",
    "    # @staticmethod\n",
    "    # def measure_progress(y, attribute, target, criterion: str = 'entropy'):\n",
    "    #     size = len(y)\n",
    "    #     lte, gt = attribute <= target, attribute > target\n",
    "    #     total_e = DecisionTreeBuilder.compute_impurity(y, criterion=criterion)\n",
    "    #     lower_e = DecisionTreeBuilder.compute_impurity(y[lte], criterion=criterion)\n",
    "    #     upper_e = DecisionTreeBuilder.compute_impurity(y[gt], criterion=criterion)\n",
    "    #     lower_w = np.count_nonzero(lte) / size\n",
    "    #     upper_w = np.count_nonzero(gt) / size\n",
    "    #\n",
    "    #     return total_e - (lower_w * lower_e + upper_w * upper_e)\n",
    "    #\n",
    "    # @staticmethod\n",
    "    # def compute_information_gain(samples, attribute, target) -> float:\n",
    "    #     return ID3DecisionTreeBuilder.measure_progress(samples, attribute, target)\n",
    "    #     # classes, frequencies = value_counts(samples, normalise=True)\n",
    "    #     # total: float = DecisionTreeBuilder.compute_impurity(samples=target)\n",
    "    #     # cumulative: float = 0\n",
    "    #     # print(f'compute_information_gain')\n",
    "    #     # print(f'total: {total}')\n",
    "    #     # print(f'classes: {classes}')\n",
    "    #     # print(f'frequencies: {frequencies}')\n",
    "    #     # print(f'samples: {samples}')\n",
    "    #     # print(f'attribute: {attribute}')\n",
    "    #     # print(f'target: {target}')\n",
    "    #     # print()\n",
    "    #     # print()\n",
    "    #     # for (value, frequency) in zip(classes, frequencies):\n",
    "    #     #     print(f'class: {value}, frequency: {frequency}')\n",
    "    #     #     indices = attribute[attribute <= target]\n",
    "    #     #     # indices = [0]\n",
    "    #     #     # indices = attributes[]\n",
    "    #     #     # indices = samples[attribute] == value\n",
    "    #     #     # indices = samples[attribute == value]\n",
    "    #     #     print(f'indices {indices}')\n",
    "    #     #     # print(f'indices: {indices}')\n",
    "    #     #     contribution = DecisionTreeBuilder.compute_impurity(target[indices])\n",
    "    #     #     cumulative += frequency * contribution\n",
    "    #     # return total - cumulative\n",
    "    #\n",
    "    # @staticmethod\n",
    "    # def create_probe_values(minima, maxima):\n",
    "    #     return [v * minima + (1.0 - v) * maxima for v in [0.75, 0.5, 0.25]]  # TODO: expand values\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "outputs": [],
   "source": [
    "class Model(metaclass=abc.ABCMeta):\n",
    "\n",
    "    @abc.abstractmethod\n",
    "    def compile(self, *args, **kwargs):\n",
    "        raise NotImplementedError('Model#compile')\n",
    "\n",
    "    @abc.abstractmethod\n",
    "    def fit(self, x, y, *args, **kwargs):\n",
    "        raise NotImplementedError('Model#fit')\n",
    "\n",
    "    @abc.abstractmethod\n",
    "    def predict(self, x, *args, **kwargs):\n",
    "        raise NotImplementedError('Model#predict')\n",
    "\n",
    "\n",
    "class DecisionTree(Model):\n",
    "\n",
    "    # TODO: default value (most common class..?)\n",
    "    __builder: 'DecisionTreeBuilder' = DecisionTreeBuilder.default()\n",
    "    __root: Optional['Node'] = None\n",
    "\n",
    "    def compile(self, *args, **kwargs):\n",
    "        previous: DecisionTreeBuilder = self.__builder\n",
    "        try:\n",
    "            builder = DecisionTreeBuilder.factory(kwargs['implementation'], **kwargs)\n",
    "        except (KeyError, ValueError):\n",
    "            builder = previous\n",
    "        self.__builder = builder\n",
    "\n",
    "    def fit(self, x, y, *args, **kwargs):\n",
    "        self.__root = self.builder.build(x, y)\n",
    "\n",
    "    def predict(self, x, *args, **kwargs):\n",
    "        tree: Node = self.root\n",
    "        samples = x.to_dict(orient='records')\n",
    "        return np.asarray([tree.eval(sample) for sample in samples])\n",
    "\n",
    "    @property\n",
    "    def builder(self) -> 'DecisionTreeBuilder':\n",
    "        return require(self.__builder, 'builder')\n",
    "\n",
    "    @property\n",
    "    def root(self) -> 'Node':\n",
    "        return require(self.__root, 'root')\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Section 4 - Implementation"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data\n",
      "     sepal length (cm)  sepal width (cm)  petal length (cm)  petal width (cm)\n",
      "0                  5.1               3.5                1.4               0.2\n",
      "1                  4.9               3.0                1.4               0.2\n",
      "2                  4.7               3.2                1.3               0.2\n",
      "3                  4.6               3.1                1.5               0.2\n",
      "4                  5.0               3.6                1.4               0.2\n",
      "..                 ...               ...                ...               ...\n",
      "145                6.7               3.0                5.2               2.3\n",
      "146                6.3               2.5                5.0               1.9\n",
      "147                6.5               3.0                5.2               2.0\n",
      "148                6.2               3.4                5.4               2.3\n",
      "149                5.9               3.0                5.1               1.8\n",
      "\n",
      "[150 rows x 4 columns]\n",
      "\n",
      "Targets\n",
      "0      0\n",
      "1      0\n",
      "2      0\n",
      "3      0\n",
      "4      0\n",
      "      ..\n",
      "145    2\n",
      "146    2\n",
      "147    2\n",
      "148    2\n",
      "149    2\n",
      "Name: target, Length: 150, dtype: int64\n",
      "\n",
      "1  |---  lookup: sepal width (cm) 2.0\n",
      "2  |------  class: 1.0\n",
      "1  |---  lookup: sepal width (cm) 2.2\n",
      "2  |------  lookup: sepal length (cm) 6.0\n",
      "3  |---------  lookup: petal length (cm) 4.0\n",
      "4  |------------  class: 1.0\n",
      "3  |---------  lookup: petal length (cm) 5.0\n",
      "4  |------------  class: 2.0\n",
      "2  |------  lookup: sepal length (cm) 6.2\n",
      "3  |---------  class: 1.0\n",
      "1  |---  lookup: sepal width (cm) 2.3\n",
      "2  |------  lookup: petal width (cm) 0.3\n",
      "3  |---------  class: 0.0\n",
      "2  |------  lookup: petal width (cm) 1.0\n",
      "3  |---------  class: 1.0\n",
      "2  |------  lookup: petal width (cm) 1.3\n",
      "3  |---------  class: 1.0\n",
      "1  |---  lookup: sepal width (cm) 2.4\n",
      "2  |------  class: 1.0\n",
      "1  |---  lookup: sepal width (cm) 2.5\n",
      "2  |------  lookup: petal width (cm) 1.1\n",
      "3  |---------  class: 1.0\n",
      "2  |------  lookup: petal width (cm) 1.3\n",
      "3  |---------  class: 1.0\n",
      "2  |------  lookup: petal width (cm) 1.5\n",
      "3  |---------  class: 1.0\n",
      "2  |------  lookup: petal width (cm) 1.7\n",
      "3  |---------  class: 2.0\n",
      "2  |------  lookup: petal width (cm) 1.8\n",
      "3  |---------  class: 2.0\n",
      "2  |------  lookup: petal width (cm) 1.9\n",
      "3  |---------  class: 2.0\n",
      "2  |------  lookup: petal width (cm) 2.0\n",
      "3  |---------  class: 2.0\n",
      "1  |---  lookup: sepal width (cm) 2.6\n",
      "2  |------  lookup: petal width (cm) 1.0\n",
      "3  |---------  class: 1.0\n",
      "2  |------  lookup: petal width (cm) 1.2\n",
      "3  |---------  class: 1.0\n",
      "2  |------  lookup: petal width (cm) 1.4\n",
      "3  |---------  class: 2.0\n",
      "2  |------  lookup: petal width (cm) 2.3\n",
      "3  |---------  class: 2.0\n",
      "1  |---  lookup: sepal width (cm) 2.7\n",
      "2  |------  lookup: sepal length (cm) 5.2\n",
      "3  |---------  class: 1.0\n",
      "2  |------  lookup: sepal length (cm) 5.6\n",
      "3  |---------  class: 1.0\n",
      "2  |------  lookup: sepal length (cm) 5.8\n",
      "3  |---------  lookup: petal length (cm) 3.9\n",
      "4  |------------  class: 1.0\n",
      "3  |---------  lookup: petal length (cm) 4.1\n",
      "4  |------------  class: 1.0\n",
      "3  |---------  lookup: petal length (cm) 5.1\n",
      "4  |------------  class: 2.0\n",
      "2  |------  lookup: sepal length (cm) 6.0\n",
      "3  |---------  class: 1.0\n",
      "2  |------  lookup: sepal length (cm) 6.3\n",
      "3  |---------  class: 2.0\n",
      "2  |------  lookup: sepal length (cm) 6.4\n",
      "3  |---------  class: 2.0\n",
      "1  |---  lookup: sepal width (cm) 2.8\n",
      "2  |------  lookup: petal width (cm) 1.2\n",
      "3  |---------  class: 1.0\n",
      "2  |------  lookup: petal width (cm) 1.3\n",
      "3  |---------  class: 1.0\n",
      "2  |------  lookup: petal width (cm) 1.4\n",
      "3  |---------  class: 1.0\n",
      "2  |------  lookup: petal width (cm) 1.5\n",
      "3  |---------  lookup: sepal length (cm) 6.3\n",
      "4  |------------  class: 2.0\n",
      "3  |---------  lookup: sepal length (cm) 6.5\n",
      "4  |------------  class: 1.0\n",
      "2  |------  lookup: petal width (cm) 1.8\n",
      "3  |---------  class: 2.0\n",
      "2  |------  lookup: petal width (cm) 1.9\n",
      "3  |---------  class: 2.0\n",
      "2  |------  lookup: petal width (cm) 2.0\n",
      "3  |---------  class: 2.0\n",
      "2  |------  lookup: petal width (cm) 2.1\n",
      "3  |---------  class: 2.0\n",
      "2  |------  lookup: petal width (cm) 2.2\n",
      "3  |---------  class: 2.0\n",
      "2  |------  lookup: petal width (cm) 2.4\n",
      "3  |---------  class: 2.0\n",
      "1  |---  lookup: sepal width (cm) 2.9\n",
      "2  |------  lookup: petal width (cm) 0.2\n",
      "3  |---------  class: 0.0\n",
      "2  |------  lookup: petal width (cm) 1.3\n",
      "3  |---------  class: 1.0\n",
      "2  |------  lookup: petal width (cm) 1.4\n",
      "3  |---------  class: 1.0\n",
      "2  |------  lookup: petal width (cm) 1.5\n",
      "3  |---------  class: 1.0\n",
      "2  |------  lookup: petal width (cm) 1.8\n",
      "3  |---------  class: 2.0\n",
      "1  |---  lookup: sepal width (cm) 3.0\n",
      "2  |------  lookup: petal width (cm) 0.1\n",
      "3  |---------  class: 0.0\n",
      "2  |------  lookup: petal width (cm) 0.2\n",
      "3  |---------  class: 0.0\n",
      "2  |------  lookup: petal width (cm) 0.3\n",
      "3  |---------  class: 0.0\n",
      "2  |------  lookup: petal width (cm) 1.2\n",
      "3  |---------  class: 1.0\n",
      "2  |------  lookup: petal width (cm) 1.3\n",
      "3  |---------  class: 1.0\n",
      "2  |------  lookup: petal width (cm) 1.4\n",
      "3  |---------  class: 1.0\n",
      "2  |------  lookup: petal width (cm) 1.5\n",
      "3  |---------  class: 1.0\n",
      "2  |------  lookup: petal width (cm) 1.6\n",
      "3  |---------  class: 2.0\n",
      "2  |------  lookup: petal width (cm) 1.7\n",
      "3  |---------  class: 1.0\n",
      "2  |------  lookup: petal width (cm) 1.8\n",
      "3  |---------  class: 2.0\n",
      "2  |------  lookup: petal width (cm) 2.0\n",
      "3  |---------  class: 2.0\n",
      "2  |------  lookup: petal width (cm) 2.1\n",
      "3  |---------  class: 2.0\n",
      "2  |------  lookup: petal width (cm) 2.2\n",
      "3  |---------  class: 2.0\n",
      "2  |------  lookup: petal width (cm) 2.3\n",
      "3  |---------  class: 2.0\n",
      "1  |---  lookup: sepal width (cm) 3.1\n",
      "2  |------  lookup: sepal length (cm) 4.6\n",
      "3  |---------  class: 0.0\n",
      "2  |------  lookup: sepal length (cm) 4.8\n",
      "3  |---------  class: 0.0\n",
      "2  |------  lookup: sepal length (cm) 4.9\n",
      "3  |---------  class: 0.0\n",
      "2  |------  lookup: sepal length (cm) 6.4\n",
      "3  |---------  class: 2.0\n",
      "2  |------  lookup: sepal length (cm) 6.7\n",
      "3  |---------  lookup: petal length (cm) 4.4\n",
      "4  |------------  class: 1.0\n",
      "3  |---------  lookup: petal length (cm) 4.7\n",
      "4  |------------  class: 1.0\n",
      "3  |---------  lookup: petal length (cm) 5.6\n",
      "4  |------------  class: 2.0\n",
      "2  |------  lookup: sepal length (cm) 6.9\n",
      "3  |---------  lookup: petal length (cm) 4.9\n",
      "4  |------------  class: 1.0\n",
      "3  |---------  lookup: petal length (cm) 5.1\n",
      "4  |------------  class: 2.0\n",
      "3  |---------  lookup: petal length (cm) 5.4\n",
      "4  |------------  class: 2.0\n",
      "1  |---  lookup: sepal width (cm) 3.2\n",
      "2  |------  lookup: petal width (cm) 0.2\n",
      "3  |---------  class: 0.0\n",
      "2  |------  lookup: petal width (cm) 1.4\n",
      "3  |---------  class: 1.0\n",
      "2  |------  lookup: petal width (cm) 1.5\n",
      "3  |---------  class: 1.0\n",
      "2  |------  lookup: petal width (cm) 1.8\n",
      "3  |---------  lookup: sepal length (cm) 5.9\n",
      "4  |------------  class: 1.0\n",
      "3  |---------  lookup: sepal length (cm) 7.2\n",
      "4  |------------  class: 2.0\n",
      "2  |------  lookup: petal width (cm) 2.0\n",
      "3  |---------  class: 2.0\n",
      "2  |------  lookup: petal width (cm) 2.3\n",
      "3  |---------  class: 2.0\n",
      "1  |---  lookup: sepal width (cm) 3.3\n",
      "2  |------  lookup: sepal length (cm) 5.0\n",
      "3  |---------  class: 0.0\n",
      "2  |------  lookup: sepal length (cm) 5.1\n",
      "3  |---------  class: 0.0\n",
      "2  |------  lookup: sepal length (cm) 6.3\n",
      "3  |---------  lookup: petal length (cm) 4.7\n",
      "4  |------------  class: 1.0\n",
      "3  |---------  lookup: petal length (cm) 6.0\n",
      "4  |------------  class: 2.0\n",
      "2  |------  lookup: sepal length (cm) 6.7\n",
      "3  |---------  class: 2.0\n",
      "1  |---  lookup: sepal width (cm) 3.4\n",
      "2  |------  lookup: petal width (cm) 0.2\n",
      "3  |---------  class: 0.0\n",
      "2  |------  lookup: petal width (cm) 0.3\n",
      "3  |---------  class: 0.0\n",
      "2  |------  lookup: petal width (cm) 0.4\n",
      "3  |---------  class: 0.0\n",
      "2  |------  lookup: petal width (cm) 1.6\n",
      "3  |---------  class: 1.0\n",
      "2  |------  lookup: petal width (cm) 2.3\n",
      "3  |---------  class: 2.0\n",
      "2  |------  lookup: petal width (cm) 2.4\n",
      "3  |---------  class: 2.0\n",
      "1  |---  lookup: sepal width (cm) 3.5\n",
      "2  |------  class: 0.0\n",
      "1  |---  lookup: sepal width (cm) 3.6\n",
      "2  |------  lookup: petal length (cm) 1.0\n",
      "3  |---------  class: 0.0\n",
      "2  |------  lookup: petal length (cm) 1.4\n",
      "3  |---------  class: 0.0\n",
      "2  |------  lookup: petal length (cm) 6.1\n",
      "3  |---------  class: 2.0\n",
      "1  |---  lookup: sepal width (cm) 3.7\n",
      "2  |------  class: 0.0\n",
      "1  |---  lookup: sepal width (cm) 3.8\n",
      "2  |------  lookup: sepal length (cm) 5.1\n",
      "3  |---------  class: 0.0\n",
      "2  |------  lookup: sepal length (cm) 5.7\n",
      "3  |---------  class: 0.0\n",
      "2  |------  lookup: sepal length (cm) 7.7\n",
      "3  |---------  class: 2.0\n",
      "2  |------  lookup: sepal length (cm) 7.9\n",
      "3  |---------  class: 2.0\n",
      "1  |---  lookup: sepal width (cm) 3.9\n",
      "2  |------  class: 0.0\n",
      "1  |---  lookup: sepal width (cm) 4.0\n",
      "2  |------  class: 0.0\n",
      "1  |---  lookup: sepal width (cm) 4.1\n",
      "2  |------  class: 0.0\n",
      "1  |---  lookup: sepal width (cm) 4.2\n",
      "2  |------  class: 0.0\n",
      "1  |---  lookup: sepal width (cm) 4.4\n",
      "2  |------  class: 0.0\n",
      "Predictions:\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2.\n",
      " 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2.\n",
      " 2. 2. 2. 2. 2. 2.]\n",
      "\n",
      "\n",
      "Actual:\n",
      "0      0\n",
      "1      0\n",
      "2      0\n",
      "3      0\n",
      "4      0\n",
      "      ..\n",
      "145    2\n",
      "146    2\n",
      "147    2\n",
      "148    2\n",
      "149    2\n",
      "Name: target, Length: 150, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "def debug(node, depth: int = 0, size: int = 1):\n",
    "    padding = '|' + ('---' * depth) + ' '\n",
    "\n",
    "    def p(o):\n",
    "        print(f'{str(depth).ljust(2)} {padding} {o}')\n",
    "\n",
    "    if isinstance(node, TerminalNode):\n",
    "        p(f'class: {node.value}')\n",
    "    elif isinstance(node, BranchNode):\n",
    "        p(f'lower pivot: {node.pivot.__str__(condition=True)}')\n",
    "        debug(node.lower, depth=depth+size, size=size)\n",
    "        p(f'upper pivot: {node.pivot.__str__(condition=False)}')\n",
    "        debug(node.upper, depth=depth+size, size=size)\n",
    "    elif isinstance(node, LookupNode):\n",
    "        for (k, v) in node.mapping.items():\n",
    "            p(f'lookup: {node.feature} {k}')\n",
    "            debug(v, depth=depth+size, size=size)\n",
    "    else:\n",
    "        raise ValueError(f'Unexpected node: {node}')\n",
    "\n",
    "\n",
    "model: DecisionTree = DecisionTree()\n",
    "[xxx, yyy] = dataset(return_X_y=True, as_frame=True)\n",
    "\n",
    "# print('X', xxx, xxx.shape, xxx.dtype)\n",
    "# print('Y', yyy, yyy.shape, yyy.dtype)\n",
    "print(f'Data\\n{xxx}\\n')\n",
    "print(f'Targets\\n{yyy}\\n')\n",
    "\n",
    "model.fit(xxx, yyy)\n",
    "\n",
    "debug(model.root, 1, 1)\n",
    "\n",
    "predictions = model.predict(xxx)\n",
    "\n",
    "print(f'Predictions:\\n{predictions}\\n\\n\\nActual:\\n{yyy}')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}