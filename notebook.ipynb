{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "## Advanced Data Analytics - Algorithms and Machine Learning\n",
    "## 31005\n",
    "### Harrison Cole\n",
    "### 12962712"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Section 1 - Imports\n",
    "Imports libraries and type-definitions for use throughout the program."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "outputs": [],
   "source": [
    "import abc\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "import traceback\n",
    "\n",
    "from typing import Callable, Optional, Union, Tuple, List, Dict\n",
    "from sklearn.datasets import load_iris as dataset\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.tree import DecisionTreeClassifier, export_text\n",
    "from sklearn.model_selection import train_test_split"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Section 2 - Utility Function and Type Definitions\n",
    "Defines utility functions and types for (re)use throughout the program."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "outputs": [],
   "source": [
    "def require(value: Optional[any], field: str) -> any:\n",
    "    \"\"\"\n",
    "    A mechanism for asserting the presence of a value, and raising an exception\n",
    "    in the case of its absence.\n",
    "    :param value:\n",
    "    The value whose presence is being checked.\n",
    "    :param field:\n",
    "    A diagnostic tag indicating which value is absent.\n",
    "    \"\"\"\n",
    "    if value is None:\n",
    "        raise ValueError(f'Missing required value: \"{field}\".')\n",
    "    return value\n",
    "\n",
    "\n",
    "def default(value: Optional[any], otherwise: any) -> any:\n",
    "    \"\"\"\n",
    "    A mechanism for checking for the presence of a value, and supplying a default value\n",
    "    in the case of its absence.\n",
    "    :param value:\n",
    "    The value whose presence is being checked.\n",
    "    :param otherwise:\n",
    "    The default value to return in the case of it's absence.\n",
    "    \"\"\"\n",
    "    return otherwise if value is None else value\n",
    "\n",
    "\n",
    "def value_counts(elements, normalise: bool = True) -> tuple:\n",
    "    \"\"\"\n",
    "    A mechanism for counting the occurrences of each unique value in a set of elements.\n",
    "    :param elements:\n",
    "    The set of elements.\n",
    "    :param normalise:\n",
    "    Whether or not to return the relative frequencies of the unique values.\n",
    "    :return:\n",
    "    The values and their corresponding representation within the set of elements\n",
    "    as a tuple of arrays.\n",
    "    \"\"\"\n",
    "    values, counts = np.unique(elements, return_counts=True)\n",
    "    if normalise:\n",
    "        return values, counts / np.sum(counts)\n",
    "    return values, counts\n",
    "\n",
    "def majority_class_index(elements):\n",
    "    \"\"\"\n",
    "    A mechanism for returning the index of the class with the greatest representation\n",
    "    in a set of elements.\n",
    "    :param elements:\n",
    "    The set of elements.\n",
    "    \"\"\"\n",
    "    _, counts = value_counts(elements, normalise=False)\n",
    "    return np.argmax(counts)\n",
    "\n",
    "FeatureType = Union[str, int]\n",
    "NumericType = Union[int, float]\n",
    "PredicateType = Callable[[any], bool]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Section 3 - Data-structures, Interfaces and Implementations\n",
    "Defines the API and data-structures available for use throughout this program. Where applicable, effort is taken\n",
    "to program by contract against the interface rather than the implementation."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Section 3.1 - Split Criterion Metrics"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "outputs": [],
   "source": [
    "class SplitCriterionMetric(metaclass=abc.ABCMeta):\n",
    "    \"\"\"\n",
    "    An interface for computing the measure of quality produced by splitting the set of items across\n",
    "    the axis of a given variable at each step of computation during the tree building process.\n",
    "    \"\"\"\n",
    "\n",
    "    @abc.abstractmethod\n",
    "    def compute(self, frequencies) -> float:\n",
    "        \"\"\"\n",
    "        Computes a measure of quality, usually the homogeneity (\"sameness\") of the target class, represented by the\n",
    "        frequencies of each target class instance within a subset of the dataset.\n",
    "        :param frequencies:\n",
    "        The frequencies of each target class instance within this subset.\n",
    "        :return:\n",
    "        A floating point value where higher values indicate a higher degree of homogeneity.\n",
    "        \"\"\"\n",
    "        pass\n",
    "\n",
    "\n",
    "class Entropy(SplitCriterionMetric):\n",
    "\n",
    "    def compute(self, frequencies) -> float:\n",
    "        \"\"\"\n",
    "        Computes the entropy of the target class within a subset of the dataset.\n",
    "        :param frequencies:\n",
    "        The frequencies of each class instance within this subset.\n",
    "        :return:\n",
    "        A measure of the randomness of the distribution of each target class instance within this subset.\n",
    "        \"\"\"\n",
    "        eps=1e-9\n",
    "        return -(frequencies * np.log2(frequencies + eps)).sum()\n",
    "\n",
    "\n",
    "class GiniImpurity(SplitCriterionMetric):\n",
    "\n",
    "    def compute(self, frequencies) -> float:\n",
    "        \"\"\"\n",
    "        Computes the Gini impurity of the target class within a subset of the dataset.\n",
    "        :param frequencies:\n",
    "        The frequencies of each class instance within this subset.\n",
    "        :return:\n",
    "        A measure of how often a randomly chosen element from the dataset would be incorrectly labelled if\n",
    "        it was labelled according to the distribution of class instances within this subset.\n",
    "        \"\"\"\n",
    "        return 1 - np.sum(np.square(frequencies))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Section 3.2 - Pivot"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "outputs": [],
   "source": [
    "class Pivot:\n",
    "    \"\"\"\n",
    "    A component class that captures and describes an arbitrary predicate that is\n",
    "    used as a pivot point for splitting a set of elements.\n",
    "    i.e.\n",
    "    elements = [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10]\n",
    "    predicate = lambda e: e <= 5\n",
    "    pivot = Pivot(predicate, (, ))\n",
    "    splits = [pivot.split(e) for e in elements]\n",
    "    [T, T, T, T, T, T, F, F, F, F, F]\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, predicate: PredicateType, info: Tuple[any, any, str, str]):\n",
    "        self.__predicate = require(predicate, 'predicate')\n",
    "        self.__info = require(info, 'info')\n",
    "\n",
    "    @property\n",
    "    def predicate(self) -> PredicateType:\n",
    "        \"\"\"\n",
    "        A property returning the predicate captured in this pivot.\n",
    "        \"\"\"\n",
    "        return self.__predicate\n",
    "\n",
    "    def attribute(self) -> any:\n",
    "        \"\"\"\n",
    "        The value of the variable being pivoted upon.\n",
    "        \"\"\"\n",
    "        return self.__info[0]\n",
    "\n",
    "    def point(self) -> any:\n",
    "        \"\"\"\n",
    "        The value(s) of the pivot point.\n",
    "        \"\"\"\n",
    "        return self.__info[1]\n",
    "\n",
    "    def true_condition(self) -> str:\n",
    "        \"\"\"\n",
    "        The affirmative textual representation of the predicate.\n",
    "        \"\"\"\n",
    "        return self.__info[2]\n",
    "\n",
    "    def false_condition(self) -> str:\n",
    "        \"\"\"\n",
    "        The negative textual representation of the predicate.\n",
    "        :return:\n",
    "        \"\"\"\n",
    "        return self.__info[3]\n",
    "\n",
    "    def split(self, value: any) -> bool:\n",
    "        \"\"\"\n",
    "        A mechanism for applying the predicate upon an element.\n",
    "        :param value:\n",
    "        The value upon which the predicate is applied.\n",
    "        \"\"\"\n",
    "        return self.predicate(value)\n",
    "\n",
    "    @staticmethod\n",
    "    def continuous(attribute: FeatureType, point: NumericType) -> 'Pivot':\n",
    "        \"\"\"\n",
    "        A static factory method for building a pivot that operates upon continuous (numerical)\n",
    "        values.\n",
    "        :param attribute:\n",
    "        The name (str) or index (int) that represents the key of the attribute value\n",
    "        upon which the pivot is applied within each element of a set of homogenous elements.\n",
    "        :param point:\n",
    "        The discrete value that represents the pivot point.\n",
    "        :return:\n",
    "        A pivot in the form of: lambda value: value[attribute] <= point\n",
    "        \"\"\"\n",
    "        def predicate(value: any) -> bool:\n",
    "            return value[attribute] <= point\n",
    "        return Pivot(predicate=predicate, info=(attribute, point, '<=', '>'))\n",
    "\n",
    "    def __str__(self, condition: bool = True) -> str:\n",
    "        \"\"\"\n",
    "        The human-intelligible, textual representation of this pivot.\n",
    "        :param condition:\n",
    "        The negation of the predicate, if false.\n",
    "        \"\"\"\n",
    "        operator: str = self.true_condition() if condition else self.false_condition()\n",
    "        return f'x[{self.attribute()}] {operator.ljust(2)} {self.point()}'\n",
    "\n",
    "\n",
    "class NumericalPivotCandidate:\n",
    "    \"\"\"\n",
    "    A component data-structure for tracking the set of parameters that best splits a\n",
    "    continuous attribute.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, feature: FeatureType, gain: float, probe: float):\n",
    "        self.__feature = feature\n",
    "        self.__gain = gain\n",
    "        self.__probe = probe\n",
    "\n",
    "    def feature(self) -> FeatureType:\n",
    "        \"\"\"\n",
    "        The name (str) or index (int) that represents the key of the attribute that is being\n",
    "        used as a feature.\n",
    "        \"\"\"\n",
    "        return require(self.__feature, 'feature')\n",
    "\n",
    "    def gain(self) -> float:\n",
    "        \"\"\"\n",
    "        The gain yielded by this combination of feature and probe value.\n",
    "        \"\"\"\n",
    "        return require(self.__gain, 'gain')\n",
    "\n",
    "    def probe(self) -> float:\n",
    "        \"\"\"\n",
    "        The best probe value tested thus far.\n",
    "        \"\"\"\n",
    "        return require(self.__probe, 'probe')\n",
    "\n",
    "    def update(self, feature: FeatureType, gain: float, probe: float) -> bool:\n",
    "        \"\"\"\n",
    "        Compares a new parameter set with the previously best seen parameter set and\n",
    "        updates the internal state of this data-structure if the new parameter set\n",
    "        yields a better gain.\n",
    "        :param feature:\n",
    "        The feature being evaluated.\n",
    "        :param gain:\n",
    "        The gain produced by this split.\n",
    "        :param probe:\n",
    "        The probe value used in producing this split.\n",
    "        :return:\n",
    "        True if this feature combination yielded a better gain than that yielded\n",
    "        by a previous combination, otherwise, False.\n",
    "        \"\"\"\n",
    "        if gain < self.gain():\n",
    "            return False\n",
    "        self.__feature = feature\n",
    "        self.__gain = gain\n",
    "        self.__probe = probe\n",
    "        return True\n",
    "\n",
    "    @staticmethod\n",
    "    def initial() -> 'NumericalPivotCandidate':\n",
    "        \"\"\"\n",
    "        A static factory method for initialising a default NumericalPivotCandidate data-structure\n",
    "        that has not seen previous parameter combinations.\n",
    "        :return:\n",
    "        \"\"\"\n",
    "        return NumericalPivotCandidate(0, 0, 0.5)\n",
    "\n",
    "    def __str__(self):\n",
    "        \"\"\"\n",
    "        The human-intelligible, textual representation of the optimal parameter set.\n",
    "        :return:\n",
    "        \"\"\"\n",
    "        return f'feature: {self.__feature}, gain: {self.__gain}, probe: {self.__probe}'\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Section 3.3 - Node"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "outputs": [],
   "source": [
    "class Node(metaclass=abc.ABCMeta):\n",
    "    \"\"\"\n",
    "    An interface that encapsulates the logic of determining the class membership of an element\n",
    "    within the hierarchy of a decision tree.\n",
    "    \"\"\"\n",
    "\n",
    "    @abc.abstractmethod\n",
    "    def eval(self, element: any) -> any:\n",
    "        \"\"\"\n",
    "        Computes the class membership of an element, typically by means of traversing the node hierarchy\n",
    "        recursively.\n",
    "        :param element:\n",
    "        The element whose class we wish to determine.\n",
    "        :return:\n",
    "        The class membership of the given element.\n",
    "        \"\"\"\n",
    "        raise NotImplementedError('Node#eval')\n",
    "\n",
    "    @abc.abstractmethod\n",
    "    def depth(self) -> int:\n",
    "        \"\"\"\n",
    "        Computes the number of levels (children) beneath this specific node, inclusive\n",
    "        of the current node.\n",
    "        \"\"\"\n",
    "        pass\n",
    "\n",
    "    def prune(self) -> 'Node':\n",
    "        \"\"\"\n",
    "        A mechanism for producing locally optimal or more efficient node configurations\n",
    "        dependent upon a nodes internal state. This method provides no default implementation\n",
    "        as optimisation is not necessary, although desirable, to the proper functioning of\n",
    "        a decision tree.\n",
    "        \"\"\"\n",
    "        return self\n",
    "\n",
    "    @staticmethod\n",
    "    def terminate(value: any) -> 'Node':\n",
    "        \"\"\"\n",
    "        A static factory method for producing a terminal (leaf) node with the given value.\n",
    "        :param value:\n",
    "        The class membership of this terminal node.\n",
    "        \"\"\"\n",
    "        return TerminalNode(value=value)\n",
    "\n",
    "    @staticmethod\n",
    "    def branch(pivot: 'Pivot', true_branch: Optional['Node'] = None, false_branch: Optional['Node'] = None) -> 'Node':\n",
    "        \"\"\"\n",
    "        A static factory method for producing a branch (internal) node with the given pivot and true/false branch nodes.\n",
    "        Used to handle mappings with a single split.\n",
    "        :param pivot:\n",
    "        The predicate upon which elements are pivoted.\n",
    "        :param true_branch:\n",
    "        The branch elements are directed to when the predicate evaluates true.\n",
    "        :param false_branch:\n",
    "        The branch elements are directed to when the predicate evaluates false.\n",
    "        \"\"\"\n",
    "        return BranchNode(pivot=pivot, true_branch=true_branch, false_branch=false_branch)\n",
    "\n",
    "    @staticmethod\n",
    "    def lookup(mapping: Dict[any, 'Node'], feature: FeatureType) -> 'Node':\n",
    "        \"\"\"\n",
    "        A static factory method for producing a branch (internal) node with the given attribute mappings.\n",
    "        Used to handle mappings with an arbitrary number of splits.\n",
    "        :param mapping:\n",
    "        The dictionary of arbitrary key to node mappings.\n",
    "        :param feature:\n",
    "        The feature whose value is applied as the lookup key against the given mapping.\n",
    "        \"\"\"\n",
    "        return LookupNode(mapping=mapping, feature=feature)\n",
    "\n",
    "\n",
    "class TerminalNode(Node):\n",
    "    \"\"\"\n",
    "    An implementation of the Node interface that statically resolves the class membership of an element.\n",
    "    Analogous to a leaf node in standard decision tree implementations.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, value: any):\n",
    "        self.__value = require(value, 'value')\n",
    "\n",
    "    def eval(self, element: any) -> any:\n",
    "        \"\"\"\n",
    "        Computes the class membership of the given element by statically mapping it to this node's value.\n",
    "        \"\"\"\n",
    "        return self.value\n",
    "\n",
    "    def depth(self) -> int:\n",
    "        \"\"\"\n",
    "        This implementation has no children, therefore its depth is always 1.\n",
    "        \"\"\"\n",
    "        return 1\n",
    "\n",
    "    @property\n",
    "    def value(self) -> any:\n",
    "        \"\"\"\n",
    "        The class membership value that this node evaluates to.\n",
    "        \"\"\"\n",
    "        return self.__value\n",
    "\n",
    "\n",
    "class BranchNode(Node):\n",
    "    \"\"\"\n",
    "    An implementation of the Node interface that dynamically resolves the class membership of an element.\n",
    "    Analogous to an internal node in standard decision tree implementations.\n",
    "    Used to handle mappings with a single split.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, pivot: 'Pivot', true_branch: 'Node', false_branch: 'Node'):\n",
    "        self.__pivot = require(pivot, 'pivot')\n",
    "        self.__nodes = np.asarray([false_branch, true_branch])\n",
    "\n",
    "    def eval(self, element: any) -> any:\n",
    "        \"\"\"\n",
    "        Dynamically computes the class membership of the given element by mapping it to another branch, by means of\n",
    "        applying the pivot's predicate, and then recursing until arriving at a terminal node.\n",
    "        \"\"\"\n",
    "        # Optimisation: removed the conditional branch to eliminate the cost incurred by miss-predicting a branch.\n",
    "        # previous form: branch: Node = self.true_branch if self.pivot.split(element) else self.false_branch\n",
    "        index: int = int(self.pivot.split(element))\n",
    "        branch: Node = self.nodes[index]\n",
    "        return branch.eval(element)\n",
    "\n",
    "    def depth(self) -> int:\n",
    "        \"\"\"\n",
    "        Computes the depth of this node and its deepest child.\n",
    "        \"\"\"\n",
    "        levels = [child.depth() for child in self.nodes]\n",
    "        return 1 + np.amax(levels, initial=0)\n",
    "\n",
    "    def prune(self) -> 'Node':\n",
    "        \"\"\"\n",
    "        This mechanism attempts to optimise the internal structure of this node.\n",
    "        - eliminates the branch condition if possible.\n",
    "        \"\"\"\n",
    "        if isinstance(self.true_branch, TerminalNode) and isinstance(self.false_branch, TerminalNode):\n",
    "            if self.true_branch.value == self.false_branch.value:\n",
    "                return self.true_branch\n",
    "        return self\n",
    "\n",
    "    @property\n",
    "    def pivot(self) -> 'Pivot':\n",
    "        \"\"\"\n",
    "        The pivot condition of this node.\n",
    "        \"\"\"\n",
    "        return self.__pivot\n",
    "\n",
    "    @property\n",
    "    def nodes(self):\n",
    "        \"\"\"\n",
    "        The array of nodes representing each branch.\n",
    "        Always of length 2 in the form [false_branch, true_branch]\n",
    "        \"\"\"\n",
    "        return self.__nodes\n",
    "\n",
    "    @property\n",
    "    def true_branch(self) -> 'Node':\n",
    "        \"\"\"\n",
    "        The node applied when the pivot condition evaluates truthfully.\n",
    "        \"\"\"\n",
    "        return self.nodes[int(True)]\n",
    "\n",
    "    @property\n",
    "    def false_branch(self) -> 'Node':\n",
    "        \"\"\"\n",
    "        The node applied when the pivot condition evaluates falsely.\n",
    "        \"\"\"\n",
    "        return self.nodes[int(False)]\n",
    "\n",
    "\n",
    "class LookupNode(Node):\n",
    "    \"\"\"\n",
    "    An implementation of the Node interface that dynamically resolves the class membership of an element.\n",
    "    An extended version of the internal node in standard decision tree implementations that is used to handle\n",
    "    mappings with an arbitrary number of splits.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, mapping: Dict[any, 'Node'], feature: FeatureType):\n",
    "        self.__mapping = require(mapping, 'mapping')\n",
    "        self.__feature = require(feature, 'feature')\n",
    "\n",
    "    def eval(self, element: any) -> any:\n",
    "        \"\"\"\n",
    "        Dynamically computes the class membership of the given element by mapping it to another branch, by means of\n",
    "        looking up the feature value within the node's mapping, and then recursing until arriving at a terminal node.\n",
    "        \"\"\"\n",
    "        key = element[self.feature]\n",
    "        lookup: Node = require(self.mapping[key], 'lookup')\n",
    "        return lookup.eval(element)\n",
    "\n",
    "    def depth(self, level: int = 0) -> int:\n",
    "        \"\"\"\n",
    "        Computes the depth of this node and its deepest child.\n",
    "        \"\"\"\n",
    "        levels = [child.depth() for child in self.mapping.values()]\n",
    "        return 1 + np.amax(levels, initial=0)\n",
    "\n",
    "    def prune(self) -> 'Node':\n",
    "        \"\"\"\n",
    "        This mechanism attempts to optimise the internal structure of this node.\n",
    "        - eliminates the mapping if there is only one element.\n",
    "        N.B. This type of node could be subject to much further optimisation efforts.\n",
    "        \"\"\"\n",
    "        size = len(self.mapping)\n",
    "        if size == 1:\n",
    "            return next(iter(self.mapping.values()))\n",
    "        return self\n",
    "\n",
    "    @property\n",
    "    def mapping(self) -> Dict[any, 'Node']:\n",
    "        \"\"\"\n",
    "        The internal mapping between feature values and nodes.\n",
    "        \"\"\"\n",
    "        return self.__mapping\n",
    "\n",
    "    @property\n",
    "    def feature(self) -> FeatureType:\n",
    "        \"\"\"\n",
    "        The feature whose values are mapped by this node.\n",
    "        \"\"\"\n",
    "        return self.__feature\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Section 3.4 - Decision Tree Builders"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "outputs": [],
   "source": [
    "metrics: Dict[str, SplitCriterionMetric] = {\n",
    "    'entropy': Entropy(),\n",
    "    'gini': GiniImpurity()\n",
    "}\n",
    "\n",
    "DEFAULT_CRITERION: str = 'entropy'\n",
    "\n",
    "def get_metric(criterion: str) -> SplitCriterionMetric:\n",
    "    key: str = criterion if criterion in metrics.keys() else DEFAULT_CRITERION\n",
    "    return metrics.get(key)\n",
    "\n",
    "class DecisionTreeBuilder(metaclass=abc.ABCMeta):\n",
    "\n",
    "    @abc.abstractmethod\n",
    "    def build(self, x, y) -> 'Node':\n",
    "        raise NotImplementedError('DecisionTreeBuilder#build')\n",
    "\n",
    "    def apply_criterion(self, attributes, criterion: str) -> float:\n",
    "        _, probabilities = value_counts(attributes, normalise=True)\n",
    "        metric: SplitCriterionMetric = get_metric(criterion)\n",
    "        return metric.compute(frequencies=probabilities)\n",
    "\n",
    "    def information_gain_categorical(self, data, target_attribute, feature_attribute, criterion: str):\n",
    "        total_entropy = self.apply_criterion(data[target_attribute], criterion=criterion)\n",
    "        feature_entropy = self.apply_criterion(data[feature_attribute], criterion=criterion)\n",
    "        return total_entropy - feature_entropy\n",
    "\n",
    "    def information_gain_continuous(self, data, target_attribute, feature_attribute, probe, criterion: str):\n",
    "        size, target, feature = len(data), data[target_attribute], data[feature_attribute]\n",
    "        total_entropy = self.apply_criterion(target, criterion=criterion)\n",
    "        lte, gt = feature <= probe, feature > probe\n",
    "\n",
    "        lower_entropy = self.apply_criterion(target[lte], criterion=criterion) * (np.count_nonzero(lte) / size)\n",
    "        upper_entropy = self.apply_criterion(target[gt], criterion=criterion) * (np.count_nonzero(gt) / size)\n",
    "\n",
    "        return total_entropy - (lower_entropy + upper_entropy)\n",
    "\n",
    "    @staticmethod\n",
    "    def factory(implementation: str, **kwargs) -> 'DecisionTreeBuilder':\n",
    "        factories = {\n",
    "            'ID3': ID3DecisionTreeBuilder\n",
    "        }\n",
    "        constructor = require(factories.get(implementation, None), implementation)\n",
    "        return constructor(**kwargs)\n",
    "\n",
    "    @staticmethod\n",
    "    def default() -> 'DecisionTreeBuilder':\n",
    "        return DecisionTreeBuilder.factory('ID3')\n",
    "\n",
    "\n",
    "class ID3DecisionTreeBuilder(DecisionTreeBuilder):\n",
    "    \n",
    "    def build(self, x, y, criterion: str = DEFAULT_CRITERION) -> 'Node':\n",
    "        data = x.copy()\n",
    "        data[y.name] = y\n",
    "        return self._build(original=data, subset=data, features=x.columns, target=y.name, criterion=criterion)\n",
    "\n",
    "    def _build(self, original, subset, features, target: FeatureType, criterion: str, parent_class=None) -> 'Node':\n",
    "        \"\"\"\n",
    "        ID3 Algorithm as per: https://en.wikipedia.org/wiki/ID3_algorithm#Algorithm\n",
    "        \"\"\"\n",
    "        classes = np.unique(subset[target])\n",
    "        choices = len(classes)\n",
    "\n",
    "        # base case #1\n",
    "        # Every element of the subset belongs to the same class.\n",
    "        if choices <= 1:\n",
    "            return Node.terminate(classes[0])\n",
    "\n",
    "        # base case #2\n",
    "        # There are no examples in the subset, which happens when no example in the parent set was found to match a\n",
    "        # specific value of the selected attribute.\n",
    "        if len(subset) <= 0:\n",
    "            return Node.terminate(parent_class)\n",
    "\n",
    "        majority_class = classes[majority_class_index(elements=subset[target])]\n",
    "\n",
    "        # base case #3\n",
    "        # There are no more attributes to be selected, but the examples still do not belong to the same class.\n",
    "        if len(features) <= 0:\n",
    "            return Node.terminate(majority_class)\n",
    "\n",
    "        gains = np.asarray([self.information_gain_categorical(data=subset, target_attribute=target, feature_attribute=feature, criterion=criterion) for feature in features])\n",
    "\n",
    "        best_feature = features[np.argmax(gains)]\n",
    "        attribute = subset[best_feature]\n",
    "\n",
    "        remaining_features = [feature for feature in features if feature != best_feature]\n",
    "\n",
    "        subtree: Node\n",
    "\n",
    "        # noinspection PyBroadException\n",
    "        try:\n",
    "            subtree = self._build_continuous(original=original, subset=subset, features=remaining_features, target=target, criterion=criterion, parent_class=majority_class, best_feature=best_feature, attribute=attribute)\n",
    "        except:\n",
    "            subtree = self._build_categorical(original=original, subset=subset, features=remaining_features, target=target, criterion=criterion, parent_class=majority_class, best_feature=best_feature, attribute=attribute)\n",
    "\n",
    "        while (pruned := subtree.prune()) != subtree:\n",
    "            subtree = pruned\n",
    "\n",
    "        return subtree\n",
    "\n",
    "    def _build_continuous(self, original, subset, features, target, criterion: str, parent_class, best_feature, attribute) -> 'Node':\n",
    "        probes = self.create_probe_values(attribute.min(), attribute.max())\n",
    "        candidate: NumericalPivotCandidate = NumericalPivotCandidate.initial()\n",
    "        for probe in probes:\n",
    "            gain = self.information_gain_continuous(data=subset, target_attribute=target, feature_attribute=best_feature, probe=probe, criterion=criterion)\n",
    "            candidate.update(feature=best_feature, gain=gain, probe=probe)\n",
    "\n",
    "        def build_subtree(indices) -> 'Node':\n",
    "            return self._build(original=original, subset=subset[indices], features=features, target=target, criterion=criterion, parent_class=parent_class)\n",
    "\n",
    "        pivot: Pivot = Pivot.continuous(candidate.feature(), candidate.probe())\n",
    "        true_branch = build_subtree(subset[candidate.feature()] <= candidate.probe())\n",
    "        false_branch = build_subtree(subset[candidate.feature()] > candidate.probe())\n",
    "\n",
    "        return Node.branch(pivot=pivot, true_branch=true_branch, false_branch=false_branch)\n",
    "\n",
    "    def _build_categorical(self, original, subset, features, target, criterion: str, parent_class, best_feature, attribute) -> 'Node':\n",
    "        values = np.unique(attribute)\n",
    "        mapping: Dict[any, Node] = {}\n",
    "\n",
    "        for value in values:\n",
    "            data = subset.where(subset[best_feature] == value).dropna()\n",
    "            subtree = self._build(original=original, subset=data, features=features, target=target, criterion=criterion, parent_class=parent_class)\n",
    "            mapping[value] = subtree\n",
    "\n",
    "        return Node.lookup(mapping=mapping, feature=best_feature)\n",
    "\n",
    "    def create_probe_values(self, minima, maxima):\n",
    "        weights = np.arange(0.0, 1.0, 0.05)\n",
    "        return [point * minima + (1.0 - point) * maxima for point in weights]\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "outputs": [],
   "source": [
    "class Model(metaclass=abc.ABCMeta):\n",
    "\n",
    "    def compile(self, *args, **kwargs):\n",
    "        pass\n",
    "\n",
    "    @abc.abstractmethod\n",
    "    def fit(self, x, y, *args, **kwargs):\n",
    "        raise NotImplementedError('Model#fit')\n",
    "\n",
    "    @abc.abstractmethod\n",
    "    def predict(self, x, *args, **kwargs):\n",
    "        raise NotImplementedError('Model#predict')\n",
    "\n",
    "\n",
    "class DecisionTree(Model):\n",
    "\n",
    "    # TODO: default value (most common class..?)\n",
    "    __builder: 'DecisionTreeBuilder' = DecisionTreeBuilder.default()\n",
    "    __root: Optional['Node'] = None\n",
    "    __depth: Optional[int] = None\n",
    "\n",
    "    def compile(self, *args, **kwargs):\n",
    "        previous: DecisionTreeBuilder = self.__builder\n",
    "        try:\n",
    "            builder = DecisionTreeBuilder.factory(kwargs['implementation'], **kwargs)\n",
    "        except (KeyError, ValueError):\n",
    "            builder = previous\n",
    "        self.__builder = builder\n",
    "\n",
    "    def fit(self, x, y, *args, **kwargs):\n",
    "        self.__root = self.builder.build(x, y)\n",
    "        self.__depth = None\n",
    "\n",
    "    def predict(self, x, *args, **kwargs):\n",
    "        tree: Node = self.root\n",
    "        samples = x.to_dict(orient='records')\n",
    "        return np.asarray([tree.eval(sample) for sample in samples])\n",
    "\n",
    "    @property\n",
    "    def builder(self) -> 'DecisionTreeBuilder':\n",
    "        return require(self.__builder, 'builder')\n",
    "\n",
    "    @property\n",
    "    def root(self) -> 'Node':\n",
    "        return require(self.__root, 'root')\n",
    "\n",
    "    def depth(self) -> int:\n",
    "        depth: int\n",
    "        if self.__root is None:\n",
    "            # the tree has not been built.\n",
    "            depth = 0\n",
    "        elif self.__depth is not None:\n",
    "            # the depth is cached as it has previously been calculated and the tree has not changed.\n",
    "            depth = self.__depth\n",
    "        else:\n",
    "            # the depth has not been calculated prior to this invocation.\n",
    "            depth = self.__depth = self.root.depth()\n",
    "        return depth"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Section 4 - Implementation"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data\n",
      "     sepal length (cm)  sepal width (cm)  petal length (cm)  petal width (cm)\n",
      "0                  5.1               3.5                1.4               0.2\n",
      "1                  4.9               3.0                1.4               0.2\n",
      "2                  4.7               3.2                1.3               0.2\n",
      "3                  4.6               3.1                1.5               0.2\n",
      "4                  5.0               3.6                1.4               0.2\n",
      "..                 ...               ...                ...               ...\n",
      "145                6.7               3.0                5.2               2.3\n",
      "146                6.3               2.5                5.0               1.9\n",
      "147                6.5               3.0                5.2               2.0\n",
      "148                6.2               3.4                5.4               2.3\n",
      "149                5.9               3.0                5.1               1.8\n",
      "\n",
      "[150 rows x 4 columns]\n",
      "\n",
      "Targets\n",
      "0      0\n",
      "1      0\n",
      "2      0\n",
      "3      0\n",
      "4      0\n",
      "      ..\n",
      "145    2\n",
      "146    2\n",
      "147    2\n",
      "148    2\n",
      "149    2\n",
      "Name: target, Length: 150, dtype: int64\n",
      "\n",
      "MAX DEPTH: 5\n",
      "1  |--- x[sepal width (cm)] <= 3.3200000000000003\n",
      "2  |   |--- x[petal width (cm)] <= 1.78\n",
      "3  |   |   |--- x[petal length (cm)] <= 1.8049999999999997\n",
      "4  |   |   |   |--- class: 0\n",
      "3  |   |   |--- x[petal length (cm)] >  1.8049999999999997\n",
      "4  |   |   |   |--- x[sepal length (cm)] <= 7.085\n",
      "5  |   |   |   |   |--- class: 1\n",
      "4  |   |   |   |--- x[sepal length (cm)] >  7.085\n",
      "5  |   |   |   |   |--- class: 2\n",
      "2  |   |--- x[petal width (cm)] >  1.78\n",
      "3  |   |   |--- x[sepal length (cm)] <= 5.914999999999999\n",
      "4  |   |   |   |--- x[petal length (cm)] <= 4.815\n",
      "5  |   |   |   |   |--- class: 1\n",
      "4  |   |   |   |--- x[petal length (cm)] >  4.815\n",
      "5  |   |   |   |   |--- class: 2\n",
      "3  |   |   |--- x[sepal length (cm)] >  5.914999999999999\n",
      "4  |   |   |   |--- class: 2\n",
      "1  |--- x[sepal width (cm)] >  3.3200000000000003\n",
      "2  |   |--- x[petal width (cm)] <= 0.7\n",
      "3  |   |   |--- class: 0\n",
      "2  |   |--- x[petal width (cm)] >  0.7\n",
      "3  |   |   |--- x[sepal length (cm)] <= 6.095\n",
      "4  |   |   |   |--- class: 1\n",
      "3  |   |   |--- x[sepal length (cm)] >  6.095\n",
      "4  |   |   |   |--- class: 2\n",
      "Predictions\n",
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 1 2 2 2 2\n",
      " 2 2 2 2 2 2 2 2 1 2 2 2 2 2 2 2 2 2 2 2 2 2 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2]\n",
      "Actual\n",
      "0      0\n",
      "1      0\n",
      "2      0\n",
      "3      0\n",
      "4      0\n",
      "      ..\n",
      "145    2\n",
      "146    2\n",
      "147    2\n",
      "148    2\n",
      "149    2\n",
      "Name: target, Length: 150, dtype: int64\n",
      "Accuracy: 0.9733333333333334\n",
      "|--- feature_3 <= 0.80\n",
      "|   |--- class: 0\n",
      "|--- feature_3 >  0.80\n",
      "|   |--- feature_3 <= 1.75\n",
      "|   |   |--- feature_2 <= 4.95\n",
      "|   |   |   |--- feature_3 <= 1.65\n",
      "|   |   |   |   |--- class: 1\n",
      "|   |   |   |--- feature_3 >  1.65\n",
      "|   |   |   |   |--- class: 2\n",
      "|   |   |--- feature_2 >  4.95\n",
      "|   |   |   |--- feature_3 <= 1.55\n",
      "|   |   |   |   |--- class: 2\n",
      "|   |   |   |--- feature_3 >  1.55\n",
      "|   |   |   |   |--- feature_0 <= 6.95\n",
      "|   |   |   |   |   |--- class: 1\n",
      "|   |   |   |   |--- feature_0 >  6.95\n",
      "|   |   |   |   |   |--- class: 2\n",
      "|   |--- feature_3 >  1.75\n",
      "|   |   |--- feature_2 <= 4.85\n",
      "|   |   |   |--- feature_0 <= 5.95\n",
      "|   |   |   |   |--- class: 1\n",
      "|   |   |   |--- feature_0 >  5.95\n",
      "|   |   |   |   |--- class: 2\n",
      "|   |   |--- feature_2 >  4.85\n",
      "|   |   |   |--- class: 2\n",
      "\n",
      "Predictions\n",
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2]\n",
      "Actual\n",
      "0      0\n",
      "1      0\n",
      "2      0\n",
      "3      0\n",
      "4      0\n",
      "      ..\n",
      "145    2\n",
      "146    2\n",
      "147    2\n",
      "148    2\n",
      "149    2\n",
      "Name: target, Length: 150, dtype: int64\n",
      "Accuracy: 1.0\n",
      "['Index: [106 119 133 134], Ours: [1 1 1 1], Theirs: [2 2 2 2]']\n"
     ]
    }
   ],
   "source": [
    "def debug_tree(node, depth: int = 0):\n",
    "    padding = ('|   ' * depth)[:-3] + '---'\n",
    "\n",
    "    def p(o):\n",
    "        print(f'{str(depth).ljust(2)} {padding} {o}')\n",
    "\n",
    "    if isinstance(node, TerminalNode):\n",
    "        p(f'class: {node.value}')\n",
    "    elif isinstance(node, BranchNode):\n",
    "        p(f'{node.pivot.__str__(condition=True)}')\n",
    "        debug_tree(node.true_branch, depth=depth+1,)\n",
    "        p(f'{node.pivot.__str__(condition=False)}')\n",
    "        debug_tree(node.false_branch, depth=depth+1)\n",
    "    elif isinstance(node, LookupNode):\n",
    "        for (k, v) in node.mapping.items():\n",
    "            p(f'lookup: {node.feature} {k}')\n",
    "            debug_tree(v, depth=depth+1)\n",
    "    else:\n",
    "        raise ValueError(f'Unexpected node: {node}')\n",
    "\n",
    "\n",
    "model: DecisionTree = DecisionTree()\n",
    "[xxx, yyy] = dataset(return_X_y=True, as_frame=True)\n",
    "\n",
    "# ddd = {\n",
    "#     'wind_direction': ['N', 'S', 'E', 'W'],\n",
    "#     'tide': ['Low', 'High'],\n",
    "#     'swell_forecasting': ['small', 'medium', 'large'],\n",
    "#     'good_waves': ['Yes', 'No'],\n",
    "# }\n",
    "#\n",
    "# # create an empty dataframe\n",
    "# df = pd.DataFrame(columns=ddd.keys())\n",
    "#\n",
    "# np.random.seed(42)\n",
    "# for i in range(len(xxx)):\n",
    "#     df.loc[i, 'wind_direction'] = str(np.random.choice(ddd['wind_direction'], 1)[0])\n",
    "#     df.loc[i, 'tide'] = str(np.random.choice(ddd['tide'], 1)[0])\n",
    "#     df.loc[i, 'swell_forecasting'] = str(np.random.choice(ddd['swell_forecasting'], 1)[0])\n",
    "#     df.loc[i, 'good_waves'] = str(np.random.choice(ddd['good_waves'], 1)[0])\n",
    "#     df.loc[i, 'temp'] = int(np.random.random() * 26) + 1\n",
    "#     df.loc[i, 'hello'] = 'world'\n",
    "#     for attr in xxx:\n",
    "#         df.loc[i, attr] = xxx.iloc[i][attr]\n",
    "#\n",
    "# # xxx = df.drop('good_waves', 1)\n",
    "# xxx = df\n",
    "# # yyy = df['good_waves']\n",
    "\n",
    "print(f'Data\\n{xxx}\\n')\n",
    "print(f'Targets\\n{yyy}\\n')\n",
    "\n",
    "model.fit(xxx, yyy)\n",
    "\n",
    "print(f'MAX DEPTH: {model.depth()}')\n",
    "debug_tree(model.root, 1)\n",
    "\n",
    "predictions = model.predict(xxx)\n",
    "\n",
    "accuracy = accuracy_score(yyy, predictions)\n",
    "\n",
    "print(f'Predictions\\n{predictions}')\n",
    "print(f'Actual\\n{yyy}')\n",
    "print(f'Accuracy: {accuracy}')\n",
    "\n",
    "dt = DecisionTreeClassifier()\n",
    "dt.fit(xxx, yyy)\n",
    "p = dt.predict(xxx)\n",
    "print(export_text(dt))\n",
    "\n",
    "acc = accuracy_score(yyy, p)\n",
    "\n",
    "print(f'Predictions\\n{p}')\n",
    "print(f'Actual\\n{yyy}')\n",
    "print(f'Accuracy: {acc}')\n",
    "\n",
    "# differences = predictions.difference(p)\n",
    "# differences = np.nonzero(predictions - p)\n",
    "\n",
    "# differences = [f'Index: {idx}, Ours: {predictions[idx]}, Sklearns: {p[idx]}' for idx in index for index in np.nonzero(predictions - p)]\n",
    "diff = np.asarray(np.nonzero(predictions - p))\n",
    "ours = predictions[diff]\n",
    "theirs = p[diff]\n",
    "\n",
    "differences = [f'Index: {index}, Ours: {us}, Theirs: {them}' for (index, us, them) in zip(diff, ours, theirs)]\n",
    "\n",
    "print(differences)\n",
    "\n",
    "# TODO: python 3.6 compatibility (for google colab)\n",
    "# TODO: test_train_split / sampling\n",
    "# TODO: CRISP-DM\n",
    "# TODO: cleanup\n",
    "# TODO: documentation\n",
    "# TODO: dummy dataset (demonstrating edge cases) and then proper dataset (demonstrating capabilities)\n",
    "\n",
    "# interface Predicate:\n",
    "#     apply(element: any) -> bool;\n",
    "#\n",
    "# interface Node:\n",
    "#     eval(element: any) -> any;\n",
    "#\n",
    "# class BranchNode implements Node:\n",
    "#     condition: Predicate;\n",
    "#     left, right: Node;\n",
    "#\n",
    "#     eval(element: any) -> any:\n",
    "#         if condition.apply(element):\n",
    "#             return left.eval(element);\n",
    "#         else:\n",
    "#             return right.eval(element);\n",
    "#\n",
    "# class LeafNode implements Node:\n",
    "#     value: any;\n",
    "#\n",
    "#     eval(element: any) -> any:\n",
    "#         return value;"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}