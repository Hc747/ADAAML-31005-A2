{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "## Advanced Data Analytics - Algorithms and Machine Learning\n",
    "## 31005\n",
    "### Harrison Cole\n",
    "### 12962712"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Section 1 - Imports\n",
    "Imports libraries and type-definitions for use throughout the program."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "outputs": [],
   "source": [
    "import abc\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "import traceback\n",
    "\n",
    "from typing import Callable, Optional, Union, Tuple, List, Dict\n",
    "from sklearn.datasets import load_iris as dataset\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import train_test_split"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Section 2 - Utility Function Definitions\n",
    "Defines utility functions for (re)use throughout the program."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "outputs": [],
   "source": [
    "def require(value: Optional[any], field: str) -> any:\n",
    "    \"\"\"\n",
    "    A mechanism for asserting the presence of a value, and raising an exception\n",
    "    in the case of its absence.\n",
    "    :param value:\n",
    "    The value whose presence is being checked.\n",
    "    :param field:\n",
    "    A diagnostic tag indicating which value is absent.\n",
    "    \"\"\"\n",
    "    if value is None:\n",
    "        raise ValueError(f'Missing required value: \"{field}\".')\n",
    "    return value\n",
    "\n",
    "\n",
    "def default(value: Optional[any], otherwise: any) -> any:\n",
    "    \"\"\"\n",
    "    A mechanism for checking for the presence of a value, and supplying a default value\n",
    "    in the case of its absence.\n",
    "    :param value:\n",
    "    The value whose presence is being checked.\n",
    "    :param otherwise:\n",
    "    The default value to return in the case of it's absence.\n",
    "    \"\"\"\n",
    "    return otherwise if value is None else value\n",
    "\n",
    "\n",
    "def value_counts(elements, normalise: bool = True) -> tuple:\n",
    "    \"\"\"\n",
    "    A mechanism for counting the occurrences of each unique value in a set of elements.\n",
    "    :param elements:\n",
    "    The set of elements.\n",
    "    :param normalise:\n",
    "    Whether or not to return the relative frequencies of the unique values.\n",
    "    :return:\n",
    "    The values and their corresponding representation within the set of elements\n",
    "    as a tuple of arrays.\n",
    "    \"\"\"\n",
    "    values, counts = np.unique(elements, return_counts=True)\n",
    "    if normalise:\n",
    "        return values, counts / np.sum(counts)\n",
    "    return values, counts\n",
    "\n",
    "def majority_class_index(elements):\n",
    "    \"\"\"\n",
    "    A mechanism for returning the index of the class with the greatest representation\n",
    "    in a set of elements.\n",
    "    :param elements:\n",
    "    The set of elements.\n",
    "    \"\"\"\n",
    "    _, counts = value_counts(elements, normalise=False)\n",
    "    return np.argmax(counts)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Section 3 - Data-structures, Interfaces and Implementations\n",
    "Defines the API and data-structures available for use throughout this program. Where applicable, effort is taken\n",
    "to program by contract against the interface rather than the implementation."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Section 3.1 - Split Criterion Metrics"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "outputs": [],
   "source": [
    "class SplitCriterionMetric(metaclass=abc.ABCMeta):\n",
    "    \"\"\"\n",
    "    An interface for computing the measure of quality produced by splitting the set of items across\n",
    "    the axis of a given variable at each step of computation during the tree building process.\n",
    "    \"\"\"\n",
    "\n",
    "    @abc.abstractmethod\n",
    "    def compute(self, frequencies) -> float:\n",
    "        \"\"\"\n",
    "        Computes a measure of quality, usually the homogeneity (\"sameness\") of the target class, represented by the\n",
    "        frequencies of each target class instance within a subset of the dataset.\n",
    "        :param frequencies:\n",
    "        The frequencies of each target class instance within this subset.\n",
    "        :return:\n",
    "        A floating point value where higher values indicate a higher degree of homogeneity.\n",
    "        \"\"\"\n",
    "        pass\n",
    "\n",
    "\n",
    "class Entropy(SplitCriterionMetric):\n",
    "\n",
    "    def compute(self, frequencies) -> float:\n",
    "        \"\"\"\n",
    "        Computes the entropy of the target class within a subset of the dataset.\n",
    "        :param frequencies:\n",
    "        The frequencies of each class instance within this subset.\n",
    "        :return:\n",
    "        A measure of the randomness of the distribution of each target class instance within this subset.\n",
    "        \"\"\"\n",
    "        eps=1e-9\n",
    "        return -(frequencies * np.log2(frequencies + eps)).sum()\n",
    "\n",
    "\n",
    "class GiniImpurity(SplitCriterionMetric):\n",
    "\n",
    "    def compute(self, frequencies) -> float:\n",
    "        \"\"\"\n",
    "        Computes the Gini impurity of the target class within a subset of the dataset.\n",
    "        :param frequencies:\n",
    "        The frequencies of each class instance within this subset.\n",
    "        :return:\n",
    "        A measure of how often a randomly chosen element from the dataset would be incorrectly labelled if\n",
    "        it was labelled according to the distribution of class instances within this subset.\n",
    "        \"\"\"\n",
    "        return 1 - np.sum(np.square(frequencies))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Section 3.2 - Pivot"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "outputs": [],
   "source": [
    "class Pivot:\n",
    "    \"\"\"\n",
    "    A component class that captures and describes an arbitrary predicate that is\n",
    "    used as a pivot point for splitting a set of elements.\n",
    "    i.e.\n",
    "    elements = [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10]\n",
    "    predicate = lambda e: e <= 5\n",
    "    pivot = Pivot(predicate, (, ))\n",
    "    splits = [pivot.split(e) for e in elements]\n",
    "    [T, T, T, T, T, T, F, F, F, F, F]\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, predicate: Callable[[any], bool], info: Tuple[any, any, str, str]):\n",
    "        self.__predicate = require(predicate, 'predicate')\n",
    "        self.__info = require(info, 'info')\n",
    "\n",
    "    @property\n",
    "    def predicate(self) -> Callable[[any], bool]:\n",
    "        \"\"\"\n",
    "        A property returning the predicate captured in this pivot.\n",
    "        \"\"\"\n",
    "        return self.__predicate\n",
    "\n",
    "    def attribute(self) -> any:\n",
    "        \"\"\"\n",
    "        The value of the variable being pivoted upon.\n",
    "        \"\"\"\n",
    "        return self.__info[0]\n",
    "\n",
    "    def point(self) -> any:\n",
    "        \"\"\"\n",
    "        The value(s) of the pivot point.\n",
    "        \"\"\"\n",
    "        return self.__info[1]\n",
    "\n",
    "    def true_condition(self) -> str:\n",
    "        \"\"\"\n",
    "        The affirmative textual representation of the predicate.\n",
    "        \"\"\"\n",
    "        return self.__info[2]\n",
    "\n",
    "    def false_condition(self) -> str:\n",
    "        \"\"\"\n",
    "        The negative textual representation of the predicate.\n",
    "        :return:\n",
    "        \"\"\"\n",
    "        return self.__info[3]\n",
    "\n",
    "    def split(self, value: any) -> bool:\n",
    "        \"\"\"\n",
    "        A mechanism for applying the predicate upon an element.\n",
    "        :param value:\n",
    "        The value upon which the predicate is applied.\n",
    "        \"\"\"\n",
    "        return self.predicate(value)\n",
    "\n",
    "    @staticmethod\n",
    "    def continuous(attribute: Union[str, int], point: Union[int, float]) -> 'Pivot':\n",
    "        \"\"\"\n",
    "        A static factory method for building a pivot that operates upon continuous (numerical)\n",
    "        values.\n",
    "        :param attribute:\n",
    "        The name (str) or index (int) that represents the key of the attribute value\n",
    "        upon which the pivot is applied within each element of a set of homogenous elements.\n",
    "        :param point:\n",
    "        The discrete value that represents the pivot point.\n",
    "        :return:\n",
    "        A pivot in the form of: lambda value: value[attribute] <= point\n",
    "        \"\"\"\n",
    "        def predicate(value: any) -> bool:\n",
    "            return value[attribute] <= point\n",
    "        return Pivot(predicate=predicate, info=(attribute, point, '<=', '>'))\n",
    "\n",
    "    def __str__(self, condition: bool = True) -> str:\n",
    "        \"\"\"\n",
    "        The human-intelligible, textual representation of this pivot.\n",
    "        :param condition:\n",
    "        The negation of the predicate, if false.\n",
    "        \"\"\"\n",
    "        operator: str = self.true_condition() if condition else self.false_condition()\n",
    "        return f'x[{self.attribute()}] {operator.ljust(2)} {self.point()}'\n",
    "\n",
    "\n",
    "class NumericalPivotCandidate:\n",
    "    \"\"\"\n",
    "    A component data-structure for tracking the set of parameters that best splits a\n",
    "    continuous attribute.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, feature: Union[str, int], gain: float, probe: float):\n",
    "        self.__feature = feature\n",
    "        self.__gain = gain\n",
    "        self.__probe = probe\n",
    "\n",
    "    def feature(self) -> Union[str, int]:\n",
    "        \"\"\"\n",
    "        The name (str) or index (int) that represents the key of the attribute that is being\n",
    "        used as a feature.\n",
    "        \"\"\"\n",
    "        return require(self.__feature, 'feature')\n",
    "\n",
    "    def gain(self) -> float:\n",
    "        \"\"\"\n",
    "        The gain yielded by this combination of feature and probe value.\n",
    "        \"\"\"\n",
    "        return require(self.__gain, 'gain')\n",
    "\n",
    "    def probe(self) -> float:\n",
    "        \"\"\"\n",
    "        The best probe value tested thus far.\n",
    "        \"\"\"\n",
    "        return require(self.__probe, 'probe')\n",
    "\n",
    "    def update(self, feature: int, gain: float, probe: float) -> bool:\n",
    "        \"\"\"\n",
    "        \n",
    "        :param feature:\n",
    "        :param gain:\n",
    "        :param probe:\n",
    "        :return:\n",
    "        True if this feature combination yielded a better gain than that yielded\n",
    "        by a previous combination, otherwise, False.\n",
    "        \"\"\"\n",
    "        if gain < self.gain():\n",
    "            return False\n",
    "        self.__feature = feature\n",
    "        self.__gain = gain\n",
    "        self.__probe = probe\n",
    "        return True\n",
    "\n",
    "    @staticmethod\n",
    "    def initial() -> 'NumericalPivotCandidate':\n",
    "        return NumericalPivotCandidate(0, 0, 0.5)\n",
    "\n",
    "    def __str__(self):\n",
    "        return f'feature: {self.__feature}, gain: {self.__gain}, probe: {self.__probe}'\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "outputs": [],
   "source": [
    "class Node(metaclass=abc.ABCMeta):\n",
    "\n",
    "    @abc.abstractmethod\n",
    "    def eval(self, element: any) -> any:\n",
    "        raise NotImplementedError('Node#eval')\n",
    "\n",
    "    @abc.abstractmethod\n",
    "    def depth(self, level: int = 0) -> int:\n",
    "        pass\n",
    "\n",
    "    def prune(self) -> 'Node':\n",
    "        return self\n",
    "\n",
    "    @staticmethod\n",
    "    def terminate(value: any) -> 'Node':\n",
    "        return TerminalNode(value=value)\n",
    "\n",
    "    @staticmethod\n",
    "    def branch(pivot: 'Pivot', true_branch: Optional['Node'] = None, false_branch: Optional['Node'] = None) -> 'Node':\n",
    "        return BranchNode(pivot=pivot, true_branch=true_branch, false_branch=false_branch)\n",
    "\n",
    "    @staticmethod\n",
    "    def lookup(mapping: Dict[any, 'Node'], feature: any) -> 'Node':\n",
    "        return LookupNode(mapping=mapping, feature=feature)\n",
    "\n",
    "\n",
    "class TerminalNode(Node):\n",
    "\n",
    "    def __init__(self, value: any):\n",
    "        self.__value = require(value, 'value')\n",
    "\n",
    "    def eval(self, element: any) -> any:\n",
    "        return self.value\n",
    "\n",
    "    def depth(self, level: int = 0) -> int:\n",
    "        return level\n",
    "\n",
    "    @property\n",
    "    def value(self) -> any:\n",
    "        return require(self.__value, 'value')\n",
    "\n",
    "\n",
    "class BranchNode(Node):\n",
    "    \"\"\"\n",
    "    TODO: documentation\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, pivot: 'Pivot', true_branch: 'Node', false_branch: 'Node'):\n",
    "        self.__pivot = require(pivot, 'pivot')\n",
    "        self.__nodes = np.asarray([false_branch, true_branch])\n",
    "\n",
    "    def eval(self, element: any) -> any:\n",
    "        \"\"\"\n",
    "        :param element:\n",
    "        :return:\n",
    "        \"\"\"\n",
    "        # Optimisation: removed the conditional branch to take advantage of speculative processing.\n",
    "        # previous form: branch: Node = self.true_branch if self.pivot.split(element) else self.false_branch\n",
    "        index = int(self.pivot.split(element))\n",
    "        branch: Node = self.nodes[index]\n",
    "        return branch.eval(element)\n",
    "\n",
    "    def depth(self, level: int = 0) -> int:\n",
    "        return max(self.true_branch.depth(level=level + 1), self.false_branch.depth(level=level + 1))\n",
    "\n",
    "    def prune(self) -> 'Node':\n",
    "        if isinstance(self.true_branch, TerminalNode) and isinstance(self.false_branch, TerminalNode) and self.true_branch.value == self.false_branch.value:\n",
    "            return self.true_branch\n",
    "        return self\n",
    "\n",
    "    @property\n",
    "    def pivot(self) -> 'Pivot':\n",
    "        return self.__pivot\n",
    "\n",
    "    @property\n",
    "    def nodes(self):\n",
    "        return self.__nodes\n",
    "\n",
    "    @property\n",
    "    def true_branch(self) -> 'Node':\n",
    "        return self.nodes[int(True)]\n",
    "\n",
    "    @property\n",
    "    def false_branch(self) -> 'Node':\n",
    "        return self.nodes[int(False)]\n",
    "\n",
    "\n",
    "class LookupNode(Node):\n",
    "\n",
    "    __mapping: Dict[any, 'Node']\n",
    "    __feature: any\n",
    "\n",
    "    def __init__(self, mapping: Dict[any, 'Node'], feature: any):\n",
    "        self.__mapping = require(mapping, 'mapping')\n",
    "        self.__feature = require(feature, 'feature')\n",
    "\n",
    "    def eval(self, element: any) -> any:\n",
    "        value = element[self.feature]\n",
    "        lookup: Node = require(self.mapping[value], 'lookup')\n",
    "        return lookup.eval(element)\n",
    "\n",
    "    def depth(self, level: int = 0) -> int:\n",
    "        return max([node.depth(level=level + 1) for node in self.mapping.values()], default=level + 1)\n",
    "\n",
    "    def prune(self) -> 'Node':\n",
    "        size = len(self.mapping)\n",
    "        if size == 1:\n",
    "            return next(iter(self.mapping.values()))\n",
    "        return self\n",
    "\n",
    "    @property\n",
    "    def mapping(self) -> Dict[any, 'Node']:\n",
    "        return self.__mapping\n",
    "\n",
    "    @property\n",
    "    def feature(self) -> any:\n",
    "        return self.__feature\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "outputs": [],
   "source": [
    "entropy: SplitCriterionMetric = Entropy()\n",
    "gini: SplitCriterionMetric = GiniImpurity()\n",
    "\n",
    "class DecisionTreeBuilder(metaclass=abc.ABCMeta):\n",
    "\n",
    "    @abc.abstractmethod\n",
    "    def build(self, x, y) -> 'Node':\n",
    "        raise NotImplementedError('DecisionTreeBuilder#build')\n",
    "\n",
    "    def entropy(self, attributes, criterion: SplitCriterionMetric = entropy) -> float:\n",
    "        _, probabilities = value_counts(attributes, normalise=True)\n",
    "        return criterion.compute(frequencies=probabilities)\n",
    "\n",
    "    def information_gain_categorical(self, data, target_attribute, feature_attribute):\n",
    "        total_entropy = self.entropy(data[target_attribute])\n",
    "        feature_entropy = self.entropy(data[feature_attribute])\n",
    "        return total_entropy - feature_entropy\n",
    "\n",
    "    def information_gain_continuous(self, data, target_attribute, feature_attribute, probe):\n",
    "        size, target, feature = len(data), data[target_attribute], data[feature_attribute]\n",
    "        total_entropy = self.entropy(target)\n",
    "        lte, gt = feature <= probe, feature > probe\n",
    "\n",
    "        lower_entropy = self.entropy(target[lte]) * (np.count_nonzero(lte) / size)\n",
    "        upper_entropy = self.entropy(target[gt]) * (np.count_nonzero(gt) / size)\n",
    "\n",
    "        return total_entropy - (lower_entropy + upper_entropy)\n",
    "\n",
    "    @staticmethod\n",
    "    def factory(implementation: str, **kwargs) -> 'DecisionTreeBuilder':\n",
    "        factories = {\n",
    "            'ID3': ID3DecisionTreeBuilder\n",
    "        }\n",
    "        constructor = require(factories.get(implementation, None), implementation)\n",
    "        return constructor(**kwargs)\n",
    "\n",
    "    @staticmethod\n",
    "    def default() -> 'DecisionTreeBuilder':\n",
    "        return DecisionTreeBuilder.factory('ID3')\n",
    "\n",
    "\n",
    "class ID3DecisionTreeBuilder(DecisionTreeBuilder):\n",
    "\n",
    "    # TODO: handle continuous attributes\n",
    "    # TODO: output classes in original format...\n",
    "    # TODO: mean value\n",
    "    def build(self, x, y) -> 'Node':\n",
    "        data = x.copy()\n",
    "        data[y.name] = y\n",
    "        return self._build(original=data, subset=data, features=x.columns, target=y.name)\n",
    "\n",
    "    def _build(self, original, subset, features, target, parent_class=None) -> 'Node':\n",
    "        \"\"\"\n",
    "        ID3 Algorithm as per: https://en.wikipedia.org/wiki/ID3_algorithm#Algorithm\n",
    "        \"\"\"\n",
    "        classes = np.unique(subset[target])\n",
    "        choices = len(classes)\n",
    "\n",
    "        # base case #1\n",
    "        # Every element of the subset belongs to the same class.\n",
    "        if choices <= 1:\n",
    "            return Node.terminate(classes[0])\n",
    "\n",
    "        # base case #2\n",
    "        # There are no examples in the subset, which happens when no example in the parent set was found to match a\n",
    "        # specific value of the selected attribute.\n",
    "        if len(subset) <= 0:\n",
    "            return Node.terminate(parent_class)\n",
    "\n",
    "        majority_class = classes[majority_class_index(elements=subset[target])]\n",
    "\n",
    "        # base case #3\n",
    "        # There are no more attributes to be selected, but the examples still do not belong to the same class.\n",
    "        if len(features) <= 0:\n",
    "            return Node.terminate(majority_class)\n",
    "\n",
    "        gains = np.asarray([self.information_gain_categorical(data=subset, target_attribute=target, feature_attribute=feature) for feature in features])\n",
    "\n",
    "        best_feature = features[np.argmax(gains)]\n",
    "        attribute = subset[best_feature]\n",
    "\n",
    "        remaining_features = [feature for feature in features if feature != best_feature]\n",
    "\n",
    "        subtree: Node\n",
    "\n",
    "        # noinspection PyBroadException\n",
    "        try:\n",
    "            subtree = self._build_continuous(original=original, subset=subset, features=remaining_features, target=target, parent_class=majority_class, best_feature=best_feature, attribute=attribute)\n",
    "        except:\n",
    "            subtree = self._build_categorical(original=original, subset=subset, features=remaining_features, target=target, parent_class=majority_class, best_feature=best_feature, attribute=attribute)\n",
    "\n",
    "        while (pruned := subtree.prune()) != subtree:\n",
    "            subtree = pruned\n",
    "\n",
    "        return subtree\n",
    "\n",
    "    def _build_continuous(self, original, subset, features, target, parent_class, best_feature, attribute) -> 'Node':\n",
    "        probes = self.create_probe_values(attribute.min(), attribute.max())\n",
    "        candidate: NumericalPivotCandidate = NumericalPivotCandidate.initial()\n",
    "        for probe in probes:\n",
    "            gain = self.information_gain_continuous(data=subset, target_attribute=target, feature_attribute=best_feature, probe=probe)\n",
    "            candidate.update(feature=best_feature, gain=gain, probe=probe)\n",
    "\n",
    "        def build_subtree(indices) -> 'Node':\n",
    "            return self._build(original=original, subset=subset[indices], features=features, target=target, parent_class=parent_class)\n",
    "\n",
    "        pivot: Pivot = Pivot.continuous(candidate.feature(), candidate.probe())\n",
    "        true_branch = build_subtree(subset[candidate.feature()] <= candidate.probe())\n",
    "        false_branch = build_subtree(subset[candidate.feature()] > candidate.probe())\n",
    "\n",
    "        return Node.branch(pivot=pivot, true_branch=true_branch, false_branch=false_branch)\n",
    "\n",
    "    def _build_categorical(self, original, subset, features, target, parent_class, best_feature, attribute) -> 'Node':\n",
    "        values = np.unique(attribute)\n",
    "        mapping: Dict[any, Node] = {}\n",
    "\n",
    "        for value in values:\n",
    "            data = subset.where(subset[best_feature] == value).dropna()\n",
    "            subtree = self._build(original=original, subset=data, features=features, target=target, parent_class=parent_class)\n",
    "            mapping[value] = subtree\n",
    "\n",
    "        return Node.lookup(mapping=mapping, feature=best_feature)\n",
    "\n",
    "    # # TODO: handle categorical attributes...\n",
    "    # def build(self, x, y) -> 'Node':\n",
    "    #     classes = np.unique(y)\n",
    "    #     choices = len(classes)\n",
    "    #\n",
    "    #     if choices <= 0:  # edge-case: no choices\n",
    "    #         default_value = '<todo:default-value>'  # TODO: get default value\n",
    "    #         return Node.terminate(default_value)\n",
    "    #\n",
    "    #     if choices == 1:  # edge-case: one clear choice\n",
    "    #         return Node.terminate(classes[0])\n",
    "    #\n",
    "    #     candidate: PivotCandidate = PivotCandidate.initial()\n",
    "    #     attributes = x.shape[1]\n",
    "    #     for index in range(attributes):\n",
    "    #         # TODO: handle continuous and categorical attributes\n",
    "    #         attribute = x[:, index]  # array of all values at that index\n",
    "    #\n",
    "    #         print(f'attribute => {attribute}')\n",
    "    #         # print(f'build')\n",
    "    #         # print(f'index: {index}, attribute: {attribute}')\n",
    "    #         probes = ID3DecisionTreeBuilder.create_probe_values(attribute.min(), attribute.max())\n",
    "    #         # print(f'probes: {probes}')\n",
    "    #         for probe in probes:\n",
    "    #             gain = ID3DecisionTreeBuilder.compute_information_gain(y, attribute, probe)\n",
    "    #             # gain = np.random.random()\n",
    "    #\n",
    "    #             # gain = 0.0  # compute_gain(samples, attribute, target)\n",
    "    #             # gain = self.purity(attribute, probe, x, y)  # TODO: compute information gain\n",
    "    #             # gain = self.measure_progress(y, attribute, probe)\n",
    "    #             # gain = self.purity(attribute, )\n",
    "    #             candidate.update(feature=index, gain=gain, probe=probe)\n",
    "    #\n",
    "    #     # TODO: sanity check candidate or build pivot from candidate\n",
    "    #     pivot: Pivot = Pivot.continuous(candidate.feature(), candidate.probe())\n",
    "    #     # TODO: use or apply pivot data-structure and make more efficient...\n",
    "    #     idx_lower = x[:, candidate.feature()] <= candidate.probe()\n",
    "    #     idx_upper = x[:, candidate.feature()] > candidate.probe()\n",
    "    #\n",
    "    #     def build_index(indices) -> Node:\n",
    "    #         return self.build(x[indices], y[indices])\n",
    "    #\n",
    "    #     return Node.branch(pivot, build_index(idx_lower), build_index(idx_upper))\n",
    "    #\n",
    "    # @staticmethod\n",
    "    # def measure_progress(y, attribute, target, criterion: str = 'entropy'):\n",
    "    #     size = len(y)\n",
    "    #     lte, gt = attribute <= target, attribute > target\n",
    "    #     total_e = DecisionTreeBuilder.compute_impurity(y, criterion=criterion)\n",
    "    #     lower_e = DecisionTreeBuilder.compute_impurity(y[lte], criterion=criterion)\n",
    "    #     upper_e = DecisionTreeBuilder.compute_impurity(y[gt], criterion=criterion)\n",
    "    #     lower_w = np.count_nonzero(lte) / size\n",
    "    #     upper_w = np.count_nonzero(gt) / size\n",
    "    #\n",
    "    #     return total_e - (lower_w * lower_e + upper_w * upper_e)\n",
    "    #\n",
    "    # @staticmethod\n",
    "    # def compute_information_gain(samples, attribute, target) -> float:\n",
    "    #     return ID3DecisionTreeBuilder.measure_progress(samples, attribute, target)\n",
    "    #     # classes, frequencies = value_counts(samples, normalise=True)\n",
    "    #     # total: float = DecisionTreeBuilder.compute_impurity(samples=target)\n",
    "    #     # cumulative: float = 0\n",
    "    #     # print(f'compute_information_gain')\n",
    "    #     # print(f'total: {total}')\n",
    "    #     # print(f'classes: {classes}')\n",
    "    #     # print(f'frequencies: {frequencies}')\n",
    "    #     # print(f'samples: {samples}')\n",
    "    #     # print(f'attribute: {attribute}')\n",
    "    #     # print(f'target: {target}')\n",
    "    #     # print()\n",
    "    #     # print()\n",
    "    #     # for (value, frequency) in zip(classes, frequencies):\n",
    "    #     #     print(f'class: {value}, frequency: {frequency}')\n",
    "    #     #     indices = attribute[attribute <= target]\n",
    "    #     #     # indices = [0]\n",
    "    #     #     # indices = attributes[]\n",
    "    #     #     # indices = samples[attribute] == value\n",
    "    #     #     # indices = samples[attribute == value]\n",
    "    #     #     print(f'indices {indices}')\n",
    "    #     #     # print(f'indices: {indices}')\n",
    "    #     #     contribution = DecisionTreeBuilder.compute_impurity(target[indices])\n",
    "    #     #     cumulative += frequency * contribution\n",
    "    #     # return total - cumulative\n",
    "    #\n",
    "\n",
    "    def create_probe_values(self, minima, maxima):\n",
    "        return [v * minima + (1.0 - v) * maxima for v in [0.75, 0.5, 0.25]]  # TODO: expand values\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "outputs": [],
   "source": [
    "class Model(metaclass=abc.ABCMeta):\n",
    "\n",
    "    def compile(self, *args, **kwargs):\n",
    "        pass\n",
    "\n",
    "    @abc.abstractmethod\n",
    "    def fit(self, x, y, *args, **kwargs):\n",
    "        raise NotImplementedError('Model#fit')\n",
    "\n",
    "    @abc.abstractmethod\n",
    "    def predict(self, x, *args, **kwargs):\n",
    "        raise NotImplementedError('Model#predict')\n",
    "\n",
    "\n",
    "class DecisionTree(Model):\n",
    "\n",
    "    # TODO: default value (most common class..?)\n",
    "    __builder: 'DecisionTreeBuilder' = DecisionTreeBuilder.default()\n",
    "    __root: Optional['Node'] = None\n",
    "\n",
    "    def compile(self, *args, **kwargs):\n",
    "        previous: DecisionTreeBuilder = self.__builder\n",
    "        try:\n",
    "            builder = DecisionTreeBuilder.factory(kwargs['implementation'], **kwargs)\n",
    "        except (KeyError, ValueError):\n",
    "            builder = previous\n",
    "        self.__builder = builder\n",
    "\n",
    "    def fit(self, x, y, *args, **kwargs):\n",
    "        self.__root = self.builder.build(x, y)\n",
    "\n",
    "    def predict(self, x, *args, **kwargs):\n",
    "        tree: Node = self.root\n",
    "        samples = x.to_dict(orient='records')\n",
    "        return np.asarray([tree.eval(sample) for sample in samples])\n",
    "\n",
    "    @property\n",
    "    def builder(self) -> 'DecisionTreeBuilder':\n",
    "        return require(self.__builder, 'builder')\n",
    "\n",
    "    @property\n",
    "    def root(self) -> 'Node':\n",
    "        return require(self.__root, 'root')\n",
    "\n",
    "    def depth(self) -> int:\n",
    "        return 0 if self.root is None else self.root.depth()\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Section 4 - Implementation"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data\n",
      "     sepal length (cm)  sepal width (cm)  petal length (cm)  petal width (cm)\n",
      "0                  5.1               3.5                1.4               0.2\n",
      "1                  4.9               3.0                1.4               0.2\n",
      "2                  4.7               3.2                1.3               0.2\n",
      "3                  4.6               3.1                1.5               0.2\n",
      "4                  5.0               3.6                1.4               0.2\n",
      "..                 ...               ...                ...               ...\n",
      "145                6.7               3.0                5.2               2.3\n",
      "146                6.3               2.5                5.0               1.9\n",
      "147                6.5               3.0                5.2               2.0\n",
      "148                6.2               3.4                5.4               2.3\n",
      "149                5.9               3.0                5.1               1.8\n",
      "\n",
      "[150 rows x 4 columns]\n",
      "\n",
      "Targets\n",
      "0      0\n",
      "1      0\n",
      "2      0\n",
      "3      0\n",
      "4      0\n",
      "      ..\n",
      "145    2\n",
      "146    2\n",
      "147    2\n",
      "148    2\n",
      "149    2\n",
      "Name: target, Length: 150, dtype: int64\n",
      "\n",
      "MAX DEPTH: 4\n",
      "1  |--  truthy pivot: x[sepal width (cm)] <= 3.2\n",
      "2  |----  truthy pivot: x[petal width (cm)] <= 0.675\n",
      "3  |------  class: 0\n",
      "2  |----  falsey pivot: x[petal width (cm)] >  0.675\n",
      "3  |------  truthy pivot: x[sepal length (cm)] <= 7.0\n",
      "4  |--------  truthy pivot: x[petal length (cm)] <= 4.45\n",
      "5  |----------  class: 1\n",
      "4  |--------  falsey pivot: x[petal length (cm)] >  4.45\n",
      "5  |----------  class: 2\n",
      "3  |------  falsey pivot: x[sepal length (cm)] >  7.0\n",
      "4  |--------  class: 2\n",
      "1  |--  falsey pivot: x[sepal width (cm)] >  3.2\n",
      "2  |----  truthy pivot: x[petal width (cm)] <= 1.3\n",
      "3  |------  class: 0\n",
      "2  |----  falsey pivot: x[petal width (cm)] >  1.3\n",
      "3  |------  truthy pivot: x[sepal length (cm)] <= 6.475\n",
      "4  |--------  truthy pivot: x[petal length (cm)] <= 5.25\n",
      "5  |----------  class: 1\n",
      "4  |--------  falsey pivot: x[petal length (cm)] >  5.25\n",
      "5  |----------  class: 2\n",
      "3  |------  falsey pivot: x[sepal length (cm)] >  6.475\n",
      "4  |--------  class: 2\n",
      "Predictions\n",
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 2 2 2 1 2 2 1 1 2 1 1 1 1 2 1 1 2 1 2 1 2 1 2 2\n",
      " 1 1 2 2 2 1 1 1 1 2 2 1 2 1 1 1 1 2 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2]\n",
      "Actual\n",
      "0      0\n",
      "1      0\n",
      "2      0\n",
      "3      0\n",
      "4      0\n",
      "      ..\n",
      "145    2\n",
      "146    2\n",
      "147    2\n",
      "148    2\n",
      "149    2\n",
      "Name: target, Length: 150, dtype: int64\n",
      "Accuracy: 0.8733333333333333\n",
      "Predictions\n",
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2]\n",
      "Actual\n",
      "0      0\n",
      "1      0\n",
      "2      0\n",
      "3      0\n",
      "4      0\n",
      "      ..\n",
      "145    2\n",
      "146    2\n",
      "147    2\n",
      "148    2\n",
      "149    2\n",
      "Name: target, Length: 150, dtype: int64\n",
      "Accuracy: 1.0\n",
      "['Index: [50 51 52 54 55 58 63 66 68 70 72 73 76 77 78 83 84 86 91], Ours: [2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2], Theirs: [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]']\n"
     ]
    }
   ],
   "source": [
    "def debug_tree(node, depth: int = 0, size: int = 1):\n",
    "    padding = '|' + ('--' * depth) + ' '\n",
    "\n",
    "    def p(o):\n",
    "        print(f'{str(depth).ljust(2)} {padding} {o}')\n",
    "\n",
    "    if isinstance(node, TerminalNode):\n",
    "        p(f'class: {node.value}')\n",
    "    elif isinstance(node, BranchNode):\n",
    "        p(f'truthy pivot: {node.pivot.__str__(condition=True)}')\n",
    "        debug_tree(node.true_branch, depth=depth+size, size=size)\n",
    "        p(f'falsey pivot: {node.pivot.__str__(condition=False)}')\n",
    "        debug_tree(node.false_branch, depth=depth+size, size=size)\n",
    "    elif isinstance(node, LookupNode):\n",
    "        for (k, v) in node.mapping.items():\n",
    "            p(f'lookup: {node.feature} {k}')\n",
    "            debug_tree(v, depth=depth+size, size=size)\n",
    "    else:\n",
    "        raise ValueError(f'Unexpected node: {node}')\n",
    "\n",
    "\n",
    "model: DecisionTree = DecisionTree()\n",
    "[xxx, yyy] = dataset(return_X_y=True, as_frame=True)\n",
    "\n",
    "# ddd = {\n",
    "#     'wind_direction': ['N', 'S', 'E', 'W'],\n",
    "#     'tide': ['Low', 'High'],\n",
    "#     'swell_forecasting': ['small', 'medium', 'large'],\n",
    "#     'good_waves': ['Yes', 'No'],\n",
    "# }\n",
    "#\n",
    "# # create an empty dataframe\n",
    "# df = pd.DataFrame(columns=ddd.keys())\n",
    "#\n",
    "# np.random.seed(42)\n",
    "# for i in range(len(xxx)):\n",
    "#     df.loc[i, 'wind_direction'] = str(np.random.choice(ddd['wind_direction'], 1)[0])\n",
    "#     df.loc[i, 'tide'] = str(np.random.choice(ddd['tide'], 1)[0])\n",
    "#     df.loc[i, 'swell_forecasting'] = str(np.random.choice(ddd['swell_forecasting'], 1)[0])\n",
    "#     df.loc[i, 'good_waves'] = str(np.random.choice(ddd['good_waves'], 1)[0])\n",
    "#     df.loc[i, 'temp'] = int(np.random.random() * 26) + 1\n",
    "#     df.loc[i, 'hello'] = 'world'\n",
    "#     for attr in xxx:\n",
    "#         df.loc[i, attr] = xxx.iloc[i][attr]\n",
    "#\n",
    "# # xxx = df.drop('good_waves', 1)\n",
    "# xxx = df\n",
    "# # yyy = df['good_waves']\n",
    "\n",
    "print(f'Data\\n{xxx}\\n')\n",
    "print(f'Targets\\n{yyy}\\n')\n",
    "\n",
    "model.fit(xxx, yyy)\n",
    "\n",
    "print(f'MAX DEPTH: {model.depth()}')\n",
    "debug_tree(model.root, 1, 1)\n",
    "\n",
    "predictions = model.predict(xxx)\n",
    "\n",
    "accuracy = accuracy_score(yyy, predictions)\n",
    "\n",
    "print(f'Predictions\\n{predictions}')\n",
    "print(f'Actual\\n{yyy}')\n",
    "print(f'Accuracy: {accuracy}')\n",
    "\n",
    "dt = DecisionTreeClassifier()\n",
    "dt.fit(xxx, yyy)\n",
    "p = dt.predict(xxx)\n",
    "\n",
    "acc = accuracy_score(yyy, p)\n",
    "\n",
    "print(f'Predictions\\n{p}')\n",
    "print(f'Actual\\n{yyy}')\n",
    "print(f'Accuracy: {acc}')\n",
    "\n",
    "# differences = predictions.difference(p)\n",
    "# differences = np.nonzero(predictions - p)\n",
    "\n",
    "# differences = [f'Index: {idx}, Ours: {predictions[idx]}, Sklearns: {p[idx]}' for idx in index for index in np.nonzero(predictions - p)]\n",
    "diff = np.asarray(np.nonzero(predictions - p))\n",
    "ours = predictions[diff]\n",
    "theirs = p[diff]\n",
    "\n",
    "differences = [f'Index: {index}, Ours: {us}, Theirs: {them}' for (index, us, them) in zip(diff, ours, theirs)]\n",
    "\n",
    "print(differences)\n",
    "\n",
    "# TODO: python 3.6 compatibility (for google colab)\n",
    "# TODO: test_train_split / sampling\n",
    "# TODO: CRISP-DM\n",
    "# TODO: cleanup\n",
    "# TODO: documentation\n",
    "# TODO: dummy dataset (demonstrating edge cases) and then proper dataset (demonstrating capabilities)\n",
    "\n",
    "# interface Predicate:\n",
    "#     apply(element: any) -> bool;\n",
    "#\n",
    "# interface Node:\n",
    "#     eval(element: any) -> any;\n",
    "#\n",
    "# class BranchNode implements Node:\n",
    "#     condition: Predicate;\n",
    "#     left, right: Node;\n",
    "#\n",
    "#     eval(element: any) -> any:\n",
    "#         if condition.apply(element):\n",
    "#             return left.eval(element);\n",
    "#         else:\n",
    "#             return right.eval(element);\n",
    "#\n",
    "# class LeafNode implements Node:\n",
    "#     value: any;\n",
    "#\n",
    "#     eval(element: any) -> any:\n",
    "#         return value;"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}