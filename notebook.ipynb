{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "## Advanced Data Analytics - Algorithms and Machine Learning\n",
    "## 31005\n",
    "### Harrison Cole\n",
    "### 12962712"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Section 1 - Imports"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 596,
   "outputs": [],
   "source": [
    "import abc\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "import traceback\n",
    "\n",
    "from typing import Callable, Optional, Tuple\n",
    "from sklearn.datasets import load_iris as dataset\n",
    "from sklearn.metrics import accuracy_score\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Section 2 - Utility Function Definitions"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 597,
   "outputs": [],
   "source": [
    "def require(value: Optional[any], field: str):\n",
    "    if value is None:\n",
    "        raise ValueError(f'Missing required value: \"{field}\".')\n",
    "    return value\n",
    "\n",
    "\n",
    "def default(value: Optional[any], otherwise: any) -> any:\n",
    "    return otherwise if value is None else value\n",
    "\n",
    "\n",
    "def is_categorical(column):\n",
    "    return pd.api.types.is_categorical_dtype(column)\n",
    "\n",
    "\n",
    "def value_counts(y, normalise: bool = True):\n",
    "    values, counts = np.unique(y, return_counts=True)\n",
    "    if normalise:\n",
    "        return values, counts / np.sum(counts)\n",
    "    return values, counts\n",
    "\n",
    "def majority_class_index(data, attribute):\n",
    "    return np.argmax(np.unique(data[attribute], return_counts=True)[1])\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Section 3 - Datastructures, Interfaces and Implementations"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 598,
   "outputs": [],
   "source": [
    "class SplitCriterionFunction(metaclass=abc.ABCMeta):\n",
    "\n",
    "    @abc.abstractmethod\n",
    "    def compute(self, frequencies) -> float:\n",
    "        pass\n",
    "\n",
    "\n",
    "class Entropy(SplitCriterionFunction):\n",
    "\n",
    "    def compute(self, frequencies, eps=1e-9) -> float:\n",
    "        return -(frequencies * np.log2(frequencies + eps)).sum()\n",
    "\n",
    "\n",
    "class GiniIndex(SplitCriterionFunction):\n",
    "\n",
    "    def compute(self, frequencies) -> float:\n",
    "        return 1 - np.sum(np.square(frequencies))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 599,
   "outputs": [],
   "source": [
    "class TransformFunction(metaclass=abc.ABCMeta):\n",
    "\n",
    "    @abc.abstractmethod\n",
    "    def transform(self, value: any) -> any:\n",
    "        pass\n",
    "\n",
    "\n",
    "class IdentityTransformFunction(TransformFunction):\n",
    "\n",
    "    def transform(self, value: any) -> any:\n",
    "        return value\n",
    "\n",
    "\n",
    "class LookupTransformFunction(TransformFunction):\n",
    "\n",
    "    def __init__(self, transformer: Callable[[any], any]):\n",
    "        self.__transformer = require(transformer, 'transformer')\n",
    "\n",
    "    def transform(self, value: any) -> any:\n",
    "        return self.__transformer(value)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 600,
   "outputs": [],
   "source": [
    "class Pivot:\n",
    "\n",
    "    def __init__(self, predicate: Callable[[any], bool], info: Tuple[any, any, str, str]):\n",
    "        self.__predicate = require(predicate, 'predicate')\n",
    "        self.__info = require(info, 'info')\n",
    "\n",
    "    @property\n",
    "    def predicate(self) -> Callable[[any], bool]:\n",
    "        return self.__predicate\n",
    "\n",
    "    def attribute(self) -> any:\n",
    "        return self.__info[0]\n",
    "\n",
    "    def subject(self) -> any:\n",
    "        return self.__info[1]\n",
    "\n",
    "    def true_condition(self) -> str:\n",
    "        return self.__info[2]\n",
    "\n",
    "    def false_condition(self) -> str:\n",
    "        return self.__info[3]\n",
    "\n",
    "    def split(self, value: any) -> bool:\n",
    "        return self.predicate(value)\n",
    "\n",
    "    # TODO: rename method as this is only used for splits on continuous attributes...\n",
    "    @staticmethod\n",
    "    def continuous(attribute, probe) -> 'Pivot':\n",
    "        def predicate(value: any) -> bool:\n",
    "            return value[attribute] <= probe\n",
    "        return Pivot(predicate=predicate, info=(attribute, probe, '<=', '>'))\n",
    "\n",
    "    def __str__(self, condition: bool = True) -> str:\n",
    "        operator: str = self.true_condition() if condition else self.false_condition()\n",
    "        return f'x[{self.attribute()}] {operator.ljust(2)} {self.subject()}'\n",
    "\n",
    "\n",
    "class PivotCandidate:\n",
    "\n",
    "    def __init__(self, feature: any, gain: float, probe: float):\n",
    "        self.__feature = feature\n",
    "        self.__gain = gain\n",
    "        self.__probe = probe\n",
    "\n",
    "    def feature(self) -> any:\n",
    "        return require(self.__feature, 'feature')\n",
    "\n",
    "    def gain(self) -> float:\n",
    "        return require(self.__gain, 'gain')\n",
    "\n",
    "    def probe(self) -> float:\n",
    "        return require(self.__probe, 'probe')\n",
    "\n",
    "    def update(self, feature: int, gain: float, probe: float) -> bool:\n",
    "        if gain < self.gain():\n",
    "            return False\n",
    "        self.__feature = feature\n",
    "        self.__gain = gain\n",
    "        self.__probe = probe\n",
    "        return True\n",
    "\n",
    "    @staticmethod\n",
    "    def initial() -> 'PivotCandidate':\n",
    "        return PivotCandidate(0, 0, 0.5)\n",
    "\n",
    "    def __str__(self):\n",
    "        return f'feature: {self.__feature}, gain: {self.__gain}, probe: {self.__probe}'\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 601,
   "outputs": [],
   "source": [
    "class Node(metaclass=abc.ABCMeta):\n",
    "\n",
    "    @abc.abstractmethod\n",
    "    def eval(self, element: any) -> any:\n",
    "        raise NotImplementedError('Node#eval')\n",
    "\n",
    "    def prune(self) -> 'Node':\n",
    "        return self\n",
    "\n",
    "    @staticmethod\n",
    "    def terminate(value: any) -> 'Node':\n",
    "        return TerminalNode(value=value)\n",
    "\n",
    "    @staticmethod\n",
    "    def branch(pivot: 'Pivot', lower: Optional['Node'] = None, upper: Optional['Node'] = None) -> 'Node':\n",
    "        return BranchNode(pivot=pivot, lower=lower, upper=upper)\n",
    "\n",
    "    @staticmethod\n",
    "    def lookup(mapping: dict[any, 'Node'], feature: any) -> 'Node':\n",
    "        return LookupNode(mapping=mapping, feature=feature)\n",
    "\n",
    "\n",
    "class TerminalNode(Node):\n",
    "\n",
    "    def __init__(self, value: any):\n",
    "        self.__value = require(value, 'value')\n",
    "\n",
    "    def eval(self, element: any) -> any:\n",
    "        return self.value\n",
    "\n",
    "    @property\n",
    "    def value(self) -> any:\n",
    "        return require(self.__value, 'value')\n",
    "\n",
    "\n",
    "class BranchNode(Node):\n",
    "\n",
    "    __lower: 'Node'\n",
    "    __upper: 'Node'\n",
    "\n",
    "    def __init__(self, pivot: 'Pivot', lower: 'Node', upper: 'Node'):\n",
    "        self.__pivot = require(pivot, 'pivot')\n",
    "        self.__lower = require(lower, 'lower')\n",
    "        self.__upper = require(upper, 'upper')\n",
    "\n",
    "    def eval(self, element: any) -> any:\n",
    "        branch: Node = self.lower if self.pivot.split(element) else self.upper\n",
    "        return branch.eval(element)\n",
    "\n",
    "    def prune(self) -> 'Node':\n",
    "        if isinstance(self.lower, TerminalNode) and isinstance(self.upper, TerminalNode) and self.lower.value == self.upper.value:\n",
    "            return self.lower\n",
    "        return self\n",
    "\n",
    "    @property\n",
    "    def pivot(self) -> 'Pivot':\n",
    "        return self.__pivot\n",
    "\n",
    "    @property\n",
    "    def lower(self) -> 'Node':\n",
    "        return self.__lower\n",
    "\n",
    "    @property\n",
    "    def upper(self) -> 'Node':\n",
    "        return self.__upper\n",
    "\n",
    "\n",
    "class LookupNode(Node):\n",
    "\n",
    "    __mapping: dict[any, 'Node']\n",
    "    __feature: any\n",
    "\n",
    "    def __init__(self, mapping: dict[any, 'Node'], feature: any):\n",
    "        self.__mapping = require(mapping, 'mapping')\n",
    "        self.__feature = require(feature, 'feature')\n",
    "\n",
    "    def eval(self, element: any) -> any:\n",
    "        value = element[self.feature]\n",
    "        lookup: Node = require(self.mapping[value], 'lookup')\n",
    "        return lookup.eval(element)\n",
    "\n",
    "    def prune(self) -> 'Node':\n",
    "        size = len(self.mapping)\n",
    "        if size == 1:\n",
    "            return next(iter(self.mapping.values()))\n",
    "        return self\n",
    "\n",
    "    @property\n",
    "    def mapping(self) -> dict[any, 'Node']:\n",
    "        return self.__mapping\n",
    "\n",
    "    @property\n",
    "    def feature(self) -> any:\n",
    "        return self.__feature\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 602,
   "outputs": [],
   "source": [
    "class DecisionTreeBuilder(metaclass=abc.ABCMeta):\n",
    "\n",
    "    __entropy: 'SplitCriterionFunction' = Entropy()\n",
    "    __gini: 'SplitCriterionFunction' = GiniIndex()\n",
    "\n",
    "    @abc.abstractmethod\n",
    "    def build(self, x, y) -> 'Node':\n",
    "        raise NotImplementedError('DecisionTreeBuilder#build')\n",
    "\n",
    "    # @staticmethod\n",
    "    # def compute_impurity(samples, criterion: str = 'entropy') -> float:\n",
    "    #     _, probabilities = value_counts(samples, normalise=True)\n",
    "    #     fns = {'entropy': Entropy, 'gini': GiniIndex}\n",
    "    #     fn: SplitCriterionFunction = require(fns.get(criterion, None), criterion)()\n",
    "    #     return fn.compute(probabilities)\n",
    "\n",
    "    def entropy(self, attributes) -> float:\n",
    "        _, probabilities = value_counts(attributes, normalise=True)\n",
    "        return self.__entropy.compute(frequencies=probabilities)\n",
    "\n",
    "    def information_gain_categorical(self, data, target_attribute, feature_attribute):\n",
    "        total_entropy = self.entropy(data[target_attribute])\n",
    "        feature_entropy = self.entropy(data[feature_attribute])\n",
    "        return total_entropy - feature_entropy\n",
    "\n",
    "    def information_gain_continuous(self, data, target_attribute, feature_attribute, probe):\n",
    "        size, target, feature = len(data), data[target_attribute], data[feature_attribute]\n",
    "        total_entropy = self.entropy(target)\n",
    "        lte, gt = feature <= probe, feature > probe\n",
    "\n",
    "        lower_entropy = self.entropy(target[lte]) * (np.count_nonzero(lte) / size)\n",
    "        upper_entropy = self.entropy(target[gt]) * (np.count_nonzero(gt) / size)\n",
    "\n",
    "        return total_entropy - (lower_entropy + upper_entropy)\n",
    "\n",
    "    @staticmethod\n",
    "    def factory(implementation: str, **kwargs) -> 'DecisionTreeBuilder':\n",
    "        factories = {\n",
    "            'ID3': ID3DecisionTreeBuilder\n",
    "        }\n",
    "        constructor = require(factories.get(implementation, None), implementation)\n",
    "        return constructor(**kwargs)\n",
    "\n",
    "    @staticmethod\n",
    "    def default() -> 'DecisionTreeBuilder':\n",
    "        return DecisionTreeBuilder.factory('ID3')\n",
    "\n",
    "\n",
    "class ID3DecisionTreeBuilder(DecisionTreeBuilder):\n",
    "\n",
    "    # TODO: handle continuous attributes\n",
    "    # TODO: output classes in original format...\n",
    "    # TODO: mean value\n",
    "    def build(self, x, y) -> 'Node':\n",
    "        data = x.copy()\n",
    "        data[y.name] = y\n",
    "        return self._build(original=data, subset=data, features=x.columns, target=y.name)\n",
    "\n",
    "    def _build(self, original, subset, features, target, parent_class=None) -> 'Node':\n",
    "        \"\"\"\n",
    "        ID3 Algorithm as per: https://en.wikipedia.org/wiki/ID3_algorithm#Algorithm\n",
    "        \"\"\"\n",
    "        classes = np.unique(subset[target])\n",
    "        choices = len(classes)\n",
    "\n",
    "        # base case #1\n",
    "        # Every element of the subset belongs to the same class.\n",
    "        if choices <= 1:\n",
    "            return Node.terminate(classes[0])\n",
    "\n",
    "        # base case #2\n",
    "        # There are no examples in the subset, which happens when no example in the parent set was found to match a\n",
    "        # specific value of the selected attribute\n",
    "        if len(subset) <= 0:\n",
    "            return Node.terminate(parent_class)\n",
    "\n",
    "        majority_class = classes[majority_class_index(data=subset, attribute=target)]\n",
    "\n",
    "        # base case #3\n",
    "        # There are no more attributes to be selected, but the examples still do not belong to the same class.\n",
    "        if len(features) <= 0:\n",
    "            return Node.terminate(majority_class)\n",
    "\n",
    "        gains = np.asarray([self.information_gain_categorical(data=subset, target_attribute=target, feature_attribute=feature) for feature in features])\n",
    "\n",
    "        best_feature = features[np.argmax(gains)]\n",
    "        attribute = subset[best_feature]\n",
    "\n",
    "        remaining_features = [feature for feature in features if feature != best_feature]\n",
    "\n",
    "        subtree: Node\n",
    "\n",
    "        # noinspection PyBroadException\n",
    "        try:\n",
    "            subtree = self._build_continuous(original=original, subset=subset, features=remaining_features, target=target, parent_class=majority_class, best_feature=best_feature, attribute=attribute)\n",
    "        except:\n",
    "            subtree = self._build_categorical(original=original, subset=subset, features=remaining_features, target=target, parent_class=majority_class, best_feature=best_feature, attribute=attribute)\n",
    "\n",
    "        while (pruned := subtree.prune()) != subtree:\n",
    "            subtree = pruned\n",
    "\n",
    "        return subtree\n",
    "\n",
    "    def _build_continuous(self, original, subset, features, target, parent_class, best_feature, attribute) -> 'Node':\n",
    "        probes = self.create_probe_values(attribute.min(), attribute.max())\n",
    "        candidate: PivotCandidate = PivotCandidate.initial()\n",
    "        for probe in probes:\n",
    "            gain = self.information_gain_continuous(data=subset, target_attribute=target, feature_attribute=best_feature, probe=probe)\n",
    "            candidate.update(feature=best_feature, gain=gain, probe=probe)\n",
    "\n",
    "        def build_subtree(indices) -> 'Node':\n",
    "            return self._build(original=original, subset=subset[indices], features=features, target=target, parent_class=parent_class)\n",
    "\n",
    "        pivot: Pivot = Pivot.continuous(candidate.feature(), candidate.probe())\n",
    "        lower = build_subtree(subset[candidate.feature()] <= candidate.probe())\n",
    "        upper = build_subtree(subset[candidate.feature()] > candidate.probe())\n",
    "\n",
    "        return Node.branch(pivot=pivot, lower=lower, upper=upper)\n",
    "\n",
    "    def _build_categorical(self, original, subset, features, target, parent_class, best_feature, attribute) -> 'Node':\n",
    "        values = np.unique(attribute)\n",
    "        mapping: dict[any, Node] = {}\n",
    "\n",
    "        for value in values:\n",
    "            data = subset.where(subset[best_feature] == value).dropna()\n",
    "            subtree = self._build(original=original, subset=data, features=features, target=target, parent_class=parent_class)\n",
    "            mapping[value] = subtree\n",
    "\n",
    "        return Node.lookup(mapping=mapping, feature=best_feature)\n",
    "\n",
    "    # def _continuous(self) -> 'Node':\n",
    "    #     candidate: PivotCandidate = PivotCandidate.initial()\n",
    "    #     attributes = x.shape[1]\n",
    "    #     for index in range(attributes):\n",
    "    #         # TODO: handle continuous and categorical attributes\n",
    "    #         attribute = x[:, index]  # array of all values at that index\n",
    "    #\n",
    "    #         print(f'attribute => {attribute}')\n",
    "    #         # print(f'build')\n",
    "    #         # print(f'index: {index}, attribute: {attribute}')\n",
    "    #         probes = ID3DecisionTreeBuilder.create_probe_values(attribute.min(), attribute.max())\n",
    "    #         # print(f'probes: {probes}')\n",
    "    #         for probe in probes:\n",
    "    #             gain = ID3DecisionTreeBuilder.compute_information_gain(y, attribute, probe)\n",
    "    #             # gain = np.random.random()\n",
    "    #\n",
    "    #             # gain = 0.0  # compute_gain(samples, attribute, target)\n",
    "    #             # gain = self.purity(attribute, probe, x, y)  # TODO: compute information gain\n",
    "    #             # gain = self.measure_progress(y, attribute, probe)\n",
    "    #             # gain = self.purity(attribute, )\n",
    "    #             candidate.update(feature=index, gain=gain, probe=probe)\n",
    "    #\n",
    "    #     # TODO: sanity check candidate or build pivot from candidate\n",
    "    #     pivot: Pivot = Pivot.continuous(candidate.feature(), candidate.probe())\n",
    "    #     # TODO: use or apply pivot data-structure and make more efficient...\n",
    "    #     idx_lower = x[:, candidate.feature()] <= candidate.probe()\n",
    "    #     idx_upper = x[:, candidate.feature()] > candidate.probe()\n",
    "    #\n",
    "    #     def build_index(indices) -> Node:\n",
    "    #         return self.build(x[indices], y[indices])\n",
    "    #\n",
    "    #     return Node.branch(pivot, build_index(idx_lower), build_index(idx_upper))\n",
    "    #     pass\n",
    "\n",
    "    # def _categorical(self) -> 'Node':\n",
    "        # if is_categorical(subset[best_feature]):\n",
    "        #     print(f'{best_feature} IS CATEGORICAL')\n",
    "        # else:\n",
    "        #     print(f'{best_feature} IS NOT CATEGORICAL')\n",
    "        #\n",
    "        # # print(f'INFORMATION GAIN\\n{information_gain}\\n {best_feature_index} - {best_feature}')\n",
    "        #\n",
    "        # available_features = [feature for feature in features if feature != best_feature]\n",
    "        # values = np.unique(subset[best_feature])\n",
    "        #\n",
    "        # mapping: dict[any, Node] = {}\n",
    "        #\n",
    "        # for value in values:\n",
    "        #     data = subset.where(subset[best_feature] == value).dropna()\n",
    "        #     subtree = self._build(original=original, subset=data, features=available_features, target=target, parent_class=majority_class)\n",
    "        #     mapping[value] = subtree\n",
    "        #\n",
    "        # return Node.lookup(mapping=mapping, feature=best_feature)\n",
    "        # pass\n",
    "\n",
    "    # # TODO: handle categorical attributes...\n",
    "    # def build(self, x, y) -> 'Node':\n",
    "    #     classes = np.unique(y)\n",
    "    #     choices = len(classes)\n",
    "    #\n",
    "    #     if choices <= 0:  # edge-case: no choices\n",
    "    #         default_value = '<todo:default-value>'  # TODO: get default value\n",
    "    #         return Node.terminate(default_value)\n",
    "    #\n",
    "    #     if choices == 1:  # edge-case: one clear choice\n",
    "    #         return Node.terminate(classes[0])\n",
    "    #\n",
    "    #     candidate: PivotCandidate = PivotCandidate.initial()\n",
    "    #     attributes = x.shape[1]\n",
    "    #     for index in range(attributes):\n",
    "    #         # TODO: handle continuous and categorical attributes\n",
    "    #         attribute = x[:, index]  # array of all values at that index\n",
    "    #\n",
    "    #         print(f'attribute => {attribute}')\n",
    "    #         # print(f'build')\n",
    "    #         # print(f'index: {index}, attribute: {attribute}')\n",
    "    #         probes = ID3DecisionTreeBuilder.create_probe_values(attribute.min(), attribute.max())\n",
    "    #         # print(f'probes: {probes}')\n",
    "    #         for probe in probes:\n",
    "    #             gain = ID3DecisionTreeBuilder.compute_information_gain(y, attribute, probe)\n",
    "    #             # gain = np.random.random()\n",
    "    #\n",
    "    #             # gain = 0.0  # compute_gain(samples, attribute, target)\n",
    "    #             # gain = self.purity(attribute, probe, x, y)  # TODO: compute information gain\n",
    "    #             # gain = self.measure_progress(y, attribute, probe)\n",
    "    #             # gain = self.purity(attribute, )\n",
    "    #             candidate.update(feature=index, gain=gain, probe=probe)\n",
    "    #\n",
    "    #     # TODO: sanity check candidate or build pivot from candidate\n",
    "    #     pivot: Pivot = Pivot.continuous(candidate.feature(), candidate.probe())\n",
    "    #     # TODO: use or apply pivot data-structure and make more efficient...\n",
    "    #     idx_lower = x[:, candidate.feature()] <= candidate.probe()\n",
    "    #     idx_upper = x[:, candidate.feature()] > candidate.probe()\n",
    "    #\n",
    "    #     def build_index(indices) -> Node:\n",
    "    #         return self.build(x[indices], y[indices])\n",
    "    #\n",
    "    #     return Node.branch(pivot, build_index(idx_lower), build_index(idx_upper))\n",
    "    #\n",
    "    # @staticmethod\n",
    "    # def measure_progress(y, attribute, target, criterion: str = 'entropy'):\n",
    "    #     size = len(y)\n",
    "    #     lte, gt = attribute <= target, attribute > target\n",
    "    #     total_e = DecisionTreeBuilder.compute_impurity(y, criterion=criterion)\n",
    "    #     lower_e = DecisionTreeBuilder.compute_impurity(y[lte], criterion=criterion)\n",
    "    #     upper_e = DecisionTreeBuilder.compute_impurity(y[gt], criterion=criterion)\n",
    "    #     lower_w = np.count_nonzero(lte) / size\n",
    "    #     upper_w = np.count_nonzero(gt) / size\n",
    "    #\n",
    "    #     return total_e - (lower_w * lower_e + upper_w * upper_e)\n",
    "    #\n",
    "    # @staticmethod\n",
    "    # def compute_information_gain(samples, attribute, target) -> float:\n",
    "    #     return ID3DecisionTreeBuilder.measure_progress(samples, attribute, target)\n",
    "    #     # classes, frequencies = value_counts(samples, normalise=True)\n",
    "    #     # total: float = DecisionTreeBuilder.compute_impurity(samples=target)\n",
    "    #     # cumulative: float = 0\n",
    "    #     # print(f'compute_information_gain')\n",
    "    #     # print(f'total: {total}')\n",
    "    #     # print(f'classes: {classes}')\n",
    "    #     # print(f'frequencies: {frequencies}')\n",
    "    #     # print(f'samples: {samples}')\n",
    "    #     # print(f'attribute: {attribute}')\n",
    "    #     # print(f'target: {target}')\n",
    "    #     # print()\n",
    "    #     # print()\n",
    "    #     # for (value, frequency) in zip(classes, frequencies):\n",
    "    #     #     print(f'class: {value}, frequency: {frequency}')\n",
    "    #     #     indices = attribute[attribute <= target]\n",
    "    #     #     # indices = [0]\n",
    "    #     #     # indices = attributes[]\n",
    "    #     #     # indices = samples[attribute] == value\n",
    "    #     #     # indices = samples[attribute == value]\n",
    "    #     #     print(f'indices {indices}')\n",
    "    #     #     # print(f'indices: {indices}')\n",
    "    #     #     contribution = DecisionTreeBuilder.compute_impurity(target[indices])\n",
    "    #     #     cumulative += frequency * contribution\n",
    "    #     # return total - cumulative\n",
    "    #\n",
    "\n",
    "    def create_probe_values(self, minima, maxima):\n",
    "        return [v * minima + (1.0 - v) * maxima for v in [0.75, 0.5, 0.25]]  # TODO: expand values\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 603,
   "outputs": [],
   "source": [
    "class Model(metaclass=abc.ABCMeta):\n",
    "\n",
    "    @abc.abstractmethod\n",
    "    def compile(self, *args, **kwargs):\n",
    "        raise NotImplementedError('Model#compile')\n",
    "\n",
    "    @abc.abstractmethod\n",
    "    def fit(self, x, y, *args, **kwargs):\n",
    "        raise NotImplementedError('Model#fit')\n",
    "\n",
    "    @abc.abstractmethod\n",
    "    def predict(self, x, *args, **kwargs):\n",
    "        raise NotImplementedError('Model#predict')\n",
    "\n",
    "\n",
    "class DecisionTree(Model):\n",
    "\n",
    "    # TODO: default value (most common class..?)\n",
    "    __builder: 'DecisionTreeBuilder' = DecisionTreeBuilder.default()\n",
    "    __root: Optional['Node'] = None\n",
    "\n",
    "    def compile(self, *args, **kwargs):\n",
    "        previous: DecisionTreeBuilder = self.__builder\n",
    "        try:\n",
    "            builder = DecisionTreeBuilder.factory(kwargs['implementation'], **kwargs)\n",
    "        except (KeyError, ValueError):\n",
    "            builder = previous\n",
    "        self.__builder = builder\n",
    "\n",
    "    def fit(self, x, y, *args, **kwargs):\n",
    "        self.__root = self.builder.build(x, y)\n",
    "\n",
    "    def predict(self, x, *args, **kwargs):\n",
    "        tree: Node = self.root\n",
    "        samples = x.to_dict(orient='records')\n",
    "        return np.asarray([tree.eval(sample) for sample in samples])\n",
    "\n",
    "    @property\n",
    "    def builder(self) -> 'DecisionTreeBuilder':\n",
    "        return require(self.__builder, 'builder')\n",
    "\n",
    "    @property\n",
    "    def root(self) -> 'Node':\n",
    "        return require(self.__root, 'root')\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Section 4 - Implementation"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 604,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data\n",
      "    wind_direction  tide swell_forecasting  temp  hello\n",
      "0                E  High             small  20.0  world\n",
      "1                N   Low             large   5.0  world\n",
      "2                E   Low             small   4.0  world\n",
      "3                E  High             small  19.0  world\n",
      "4                S  High            medium  26.0  world\n",
      "..             ...   ...               ...   ...    ...\n",
      "145              S  High             small  15.0  world\n",
      "146              E   Low            medium  26.0  world\n",
      "147              N  High             large  26.0  world\n",
      "148              S   Low             small  19.0  world\n",
      "149              E   Low             small  16.0  world\n",
      "\n",
      "[150 rows x 5 columns]\n",
      "\n",
      "Targets\n",
      "0      Yes\n",
      "1       No\n",
      "2       No\n",
      "3       No\n",
      "4       No\n",
      "      ... \n",
      "145     No\n",
      "146    Yes\n",
      "147    Yes\n",
      "148    Yes\n",
      "149     No\n",
      "Name: good_waves, Length: 150, dtype: object\n",
      "\n",
      "TERMINAL\n",
      "[['N' 'Yes']\n",
      " ['S' 'Yes']\n",
      " ['W' 'No']]\n",
      "OTHERS\n",
      "[['E' <__main__.BranchNode object at 0x12f6c4970>]]\n",
      "\n",
      "TERMINAL\n",
      "[['E' 'Yes']\n",
      " ['S' 'No']\n",
      " ['W' 'No']]\n",
      "OTHERS\n",
      "[['N' <__main__.BranchNode object at 0x12f77cd90>]]\n",
      "\n",
      "TERMINAL\n",
      "[['W' 'No']]\n",
      "OTHERS\n",
      "[['E' <__main__.BranchNode object at 0x12f77c070>]\n",
      " ['N' <__main__.BranchNode object at 0x12f6c4b50>]\n",
      " ['S' <__main__.BranchNode object at 0x12f6c4ca0>]]\n",
      "\n",
      "TERMINAL\n",
      "[]\n",
      "OTHERS\n",
      "[['large' <__main__.LookupNode object at 0x12f6c4d60>]\n",
      " ['medium' <__main__.LookupNode object at 0x12f76fc70>]\n",
      " ['small' <__main__.LookupNode object at 0x130662880>]]\n",
      "\n",
      "TERMINAL\n",
      "[['E' 'Yes']]\n",
      "OTHERS\n",
      "[['N' <__main__.BranchNode object at 0x12f61fbe0>]\n",
      " ['S' <__main__.BranchNode object at 0x12f61fcd0>]\n",
      " ['W' <__main__.BranchNode object at 0x12f61f850>]]\n",
      "\n",
      "TERMINAL\n",
      "[['E' 'Yes']]\n",
      "OTHERS\n",
      "[['N' <__main__.BranchNode object at 0x12f61f370>]\n",
      " ['S' <__main__.BranchNode object at 0x12f61fdc0>]\n",
      " ['W' <__main__.BranchNode object at 0x1306624c0>]]\n",
      "\n",
      "TERMINAL\n",
      "[['S' 'Yes']\n",
      " ['W' 'No']]\n",
      "OTHERS\n",
      "[['E' <__main__.BranchNode object at 0x130941310>]\n",
      " ['N' <__main__.BranchNode object at 0x1309412b0>]]\n",
      "\n",
      "TERMINAL\n",
      "[]\n",
      "OTHERS\n",
      "[['large' <__main__.LookupNode object at 0x1309ee8e0>]\n",
      " ['medium' <__main__.LookupNode object at 0x12f77c3a0>]\n",
      " ['small' <__main__.LookupNode object at 0x12f77c730>]]\n",
      "\n",
      "TERMINAL\n",
      "[]\n",
      "OTHERS\n",
      "[['High' <__main__.LookupNode object at 0x12f76f460>]\n",
      " ['Low' <__main__.LookupNode object at 0x12f76f2b0>]]\n",
      "\n",
      "TERMINAL\n",
      "[]\n",
      "OTHERS\n",
      "[['High' <__main__.LookupNode object at 0x12f76f460>]\n",
      " ['Low' <__main__.LookupNode object at 0x12f76f2b0>]]\n",
      "\n",
      "1  |---  lookup: tide High\n",
      "2  |------  lookup: swell_forecasting large\n",
      "3  |---------  lookup: wind_direction E\n",
      "4  |------------  lower pivot: x[temp] <= 6.75\n",
      "5  |---------------  class: Yes\n",
      "4  |------------  upper pivot: x[temp] >  6.75\n",
      "5  |---------------  class: No\n",
      "3  |---------  lookup: wind_direction N\n",
      "4  |------------  class: Yes\n",
      "3  |---------  lookup: wind_direction S\n",
      "4  |------------  class: Yes\n",
      "3  |---------  lookup: wind_direction W\n",
      "4  |------------  class: No\n",
      "2  |------  lookup: swell_forecasting medium\n",
      "3  |---------  lookup: wind_direction E\n",
      "4  |------------  class: Yes\n",
      "3  |---------  lookup: wind_direction N\n",
      "4  |------------  lower pivot: x[temp] <= 7.0\n",
      "5  |---------------  class: No\n",
      "4  |------------  upper pivot: x[temp] >  7.0\n",
      "5  |---------------  class: Yes\n",
      "3  |---------  lookup: wind_direction S\n",
      "4  |------------  class: No\n",
      "3  |---------  lookup: wind_direction W\n",
      "4  |------------  class: No\n",
      "2  |------  lookup: swell_forecasting small\n",
      "3  |---------  lookup: wind_direction E\n",
      "4  |------------  lower pivot: x[temp] <= 11.0\n",
      "5  |---------------  class: Yes\n",
      "4  |------------  upper pivot: x[temp] >  11.0\n",
      "5  |---------------  class: No\n",
      "3  |---------  lookup: wind_direction N\n",
      "4  |------------  lower pivot: x[temp] <= 19.25\n",
      "5  |---------------  class: Yes\n",
      "4  |------------  upper pivot: x[temp] >  19.25\n",
      "5  |---------------  class: No\n",
      "3  |---------  lookup: wind_direction S\n",
      "4  |------------  lower pivot: x[temp] <= 13.0\n",
      "5  |---------------  class: Yes\n",
      "4  |------------  upper pivot: x[temp] >  13.0\n",
      "5  |---------------  class: No\n",
      "3  |---------  lookup: wind_direction W\n",
      "4  |------------  class: No\n",
      "1  |---  lookup: tide Low\n",
      "2  |------  lookup: swell_forecasting large\n",
      "3  |---------  lookup: wind_direction E\n",
      "4  |------------  class: Yes\n",
      "3  |---------  lookup: wind_direction N\n",
      "4  |------------  lower pivot: x[temp] <= 4.75\n",
      "5  |---------------  class: No\n",
      "4  |------------  upper pivot: x[temp] >  4.75\n",
      "5  |---------------  class: Yes\n",
      "3  |---------  lookup: wind_direction S\n",
      "4  |------------  lower pivot: x[temp] <= 14.0\n",
      "5  |---------------  class: Yes\n",
      "4  |------------  upper pivot: x[temp] >  14.0\n",
      "5  |---------------  class: No\n",
      "3  |---------  lookup: wind_direction W\n",
      "4  |------------  lower pivot: x[temp] <= 6.0\n",
      "5  |---------------  class: Yes\n",
      "4  |------------  upper pivot: x[temp] >  6.0\n",
      "5  |---------------  class: No\n",
      "2  |------  lookup: swell_forecasting medium\n",
      "3  |---------  lookup: wind_direction E\n",
      "4  |------------  class: Yes\n",
      "3  |---------  lookup: wind_direction N\n",
      "4  |------------  lower pivot: x[temp] <= 19.25\n",
      "5  |---------------  class: No\n",
      "4  |------------  upper pivot: x[temp] >  19.25\n",
      "5  |---------------  class: Yes\n",
      "3  |---------  lookup: wind_direction S\n",
      "4  |------------  lower pivot: x[temp] <= 9.0\n",
      "5  |---------------  class: Yes\n",
      "4  |------------  upper pivot: x[temp] >  9.0\n",
      "5  |---------------  class: No\n",
      "3  |---------  lookup: wind_direction W\n",
      "4  |------------  lower pivot: x[temp] <= 18.0\n",
      "5  |---------------  class: Yes\n",
      "4  |------------  upper pivot: x[temp] >  18.0\n",
      "5  |---------------  class: No\n",
      "2  |------  lookup: swell_forecasting small\n",
      "3  |---------  lookup: wind_direction E\n",
      "4  |------------  lower pivot: x[temp] <= 20.5\n",
      "5  |---------------  class: No\n",
      "4  |------------  upper pivot: x[temp] >  20.5\n",
      "5  |---------------  class: Yes\n",
      "3  |---------  lookup: wind_direction N\n",
      "4  |------------  lower pivot: x[temp] <= 5.75\n",
      "5  |---------------  class: No\n",
      "4  |------------  upper pivot: x[temp] >  5.75\n",
      "5  |---------------  class: Yes\n",
      "3  |---------  lookup: wind_direction S\n",
      "4  |------------  class: Yes\n",
      "3  |---------  lookup: wind_direction W\n",
      "4  |------------  class: No\n",
      "Predictions\n",
      "['No' 'Yes' 'No' 'No' 'No' 'No' 'Yes' 'No' 'No' 'Yes' 'No' 'Yes' 'No'\n",
      " 'Yes' 'No' 'No' 'No' 'No' 'No' 'Yes' 'Yes' 'Yes' 'Yes' 'No' 'No' 'No'\n",
      " 'No' 'Yes' 'No' 'Yes' 'Yes' 'Yes' 'No' 'Yes' 'Yes' 'No' 'No' 'Yes' 'No'\n",
      " 'Yes' 'Yes' 'Yes' 'No' 'Yes' 'No' 'No' 'Yes' 'No' 'No' 'No' 'No' 'No'\n",
      " 'No' 'No' 'No' 'No' 'Yes' 'Yes' 'No' 'No' 'No' 'No' 'Yes' 'No' 'Yes' 'No'\n",
      " 'Yes' 'Yes' 'Yes' 'No' 'No' 'No' 'Yes' 'No' 'Yes' 'Yes' 'No' 'Yes' 'No'\n",
      " 'Yes' 'No' 'No' 'No' 'Yes' 'Yes' 'Yes' 'No' 'Yes' 'Yes' 'No' 'Yes' 'Yes'\n",
      " 'No' 'Yes' 'No' 'Yes' 'No' 'No' 'Yes' 'No' 'Yes' 'Yes' 'Yes' 'Yes' 'Yes'\n",
      " 'Yes' 'Yes' 'No' 'No' 'No' 'No' 'Yes' 'Yes' 'Yes' 'No' 'Yes' 'No' 'Yes'\n",
      " 'Yes' 'No' 'Yes' 'Yes' 'No' 'Yes' 'No' 'Yes' 'Yes' 'No' 'No' 'No' 'No'\n",
      " 'No' 'Yes' 'No' 'No' 'Yes' 'No' 'Yes' 'No' 'No' 'Yes' 'No' 'Yes' 'Yes'\n",
      " 'Yes' 'No' 'Yes' 'Yes' 'Yes' 'No']\n",
      "Actual\n",
      "0      Yes\n",
      "1       No\n",
      "2       No\n",
      "3       No\n",
      "4       No\n",
      "      ... \n",
      "145     No\n",
      "146    Yes\n",
      "147    Yes\n",
      "148    Yes\n",
      "149     No\n",
      "Name: good_waves, Length: 150, dtype: object\n",
      "Accuracy: 0.7333333333333333\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/mf/zvgzl3ms129dd36gnxq2szsh0000gp/T/ipykernel_51004/761740799.py:44: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only\n",
      "  xxx = df.drop('good_waves', 1)\n"
     ]
    }
   ],
   "source": [
    "def debug_tree(node, depth: int = 0, size: int = 1):\n",
    "    padding = '|' + ('---' * depth) + ' '\n",
    "\n",
    "    def p(o):\n",
    "        print(f'{str(depth).ljust(2)} {padding} {o}')\n",
    "\n",
    "    if isinstance(node, TerminalNode):\n",
    "        p(f'class: {node.value}')\n",
    "    elif isinstance(node, BranchNode):\n",
    "        p(f'lower pivot: {node.pivot.__str__(condition=True)}')\n",
    "        debug_tree(node.lower, depth=depth+size, size=size)\n",
    "        p(f'upper pivot: {node.pivot.__str__(condition=False)}')\n",
    "        debug_tree(node.upper, depth=depth+size, size=size)\n",
    "    elif isinstance(node, LookupNode):\n",
    "        for (k, v) in node.mapping.items():\n",
    "            p(f'lookup: {node.feature} {k}')\n",
    "            debug_tree(v, depth=depth+size, size=size)\n",
    "    else:\n",
    "        raise ValueError(f'Unexpected node: {node}')\n",
    "\n",
    "\n",
    "model: DecisionTree = DecisionTree()\n",
    "# [xxx, yyy] = dataset(return_X_y=True, as_frame=True)\n",
    "\n",
    "ddd = {\n",
    "    'wind_direction': ['N', 'S', 'E', 'W'],\n",
    "    'tide': ['Low', 'High'],\n",
    "    'swell_forecasting': ['small', 'medium', 'large'],\n",
    "    'good_waves': ['Yes', 'No'],\n",
    "}\n",
    "\n",
    "# create an empty dataframe\n",
    "df = pd.DataFrame(columns=ddd.keys())\n",
    "\n",
    "np.random.seed(42)\n",
    "for i in range(150):\n",
    "    df.loc[i, 'wind_direction'] = str(np.random.choice(ddd['wind_direction'], 1)[0])\n",
    "    df.loc[i, 'tide'] = str(np.random.choice(ddd['tide'], 1)[0])\n",
    "    df.loc[i, 'swell_forecasting'] = str(np.random.choice(ddd['swell_forecasting'], 1)[0])\n",
    "    df.loc[i, 'good_waves'] = str(np.random.choice(ddd['good_waves'], 1)[0])\n",
    "    df.loc[i, 'temp'] = int(np.random.random() * 26) + 1\n",
    "    df.loc[i, 'hello'] = 'world'\n",
    "\n",
    "xxx = df.drop('good_waves', 1)\n",
    "yyy = df['good_waves']\n",
    "\n",
    "print(f'Data\\n{xxx}\\n')\n",
    "print(f'Targets\\n{yyy}\\n')\n",
    "\n",
    "model.fit(xxx, yyy)\n",
    "\n",
    "debug_tree(model.root, 1, 1)\n",
    "\n",
    "predictions = model.predict(xxx)\n",
    "\n",
    "accuracy = accuracy_score(yyy, predictions)\n",
    "\n",
    "print(f'Predictions\\n{predictions}')\n",
    "print(f'Actual\\n{yyy}')\n",
    "print(f'Accuracy: {accuracy}')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}